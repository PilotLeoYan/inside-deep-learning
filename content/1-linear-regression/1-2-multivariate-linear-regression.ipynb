{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62bb123c",
   "metadata": {},
   "source": [
    "# 1.2 - Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b184db1",
   "metadata": {},
   "source": [
    ":::{grid} 1 1 2 2\n",
    "```{card} [Open in Google Colab](https://colab.research.google.com/github/PilotLeoYan/inside-deep-learning/blob/main/content/1-linear-regression/1-2-multivariate-linear-regression.ipynb)\n",
    "```{image} ../figures/colab_logo.png\n",
    ":align: center\n",
    "```\n",
    "```{card} [Open in Jupyter NBViewer](https://nbviewer.org/github/PilotLeoYan/inside-deep-learning/blob/main/content/1-linear-regression/1-2-simple-multivariate-regression.ipynb)\n",
    "```{image} ../figures/jupyter_logo.png\n",
    ":align: center\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f5d98",
   "metadata": {},
   "source": [
    "If you already understand Simple Linear Regreession, \n",
    "then we can make things a little more complicated. \n",
    "Multivariate Linear Regression considers inputs with\n",
    "multiples *features*. This will be help us to develop a dense layer for\n",
    "the next part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580ec8c",
   "metadata": {},
   "source": [
    "```{image} ../figures/multivariate-perceptron.png\n",
    ":width: 300\n",
    ":class: hidden dark:block\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c15823",
   "metadata": {},
   "source": [
    "```{image} ../figures/multivariate-perceptron-light.png\n",
    ":width: 300\n",
    ":class: dark:hidden\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ce37c5",
   "metadata": {},
   "source": [
    "The goal of multivariate linear regression is similar to simple linear regression,\n",
    "estimate $f(\\cdot)$ by a linear approximation $\\hat{f}(\\cdot)$\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = f\\left( \\mathbf{X} \\right) + \\epsilon\n",
    "$$\n",
    "\n",
    "Note that input data $\\mathbf{X}$ is now a *matrix*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31851c0c",
   "metadata": {},
   "source": [
    "**Purpose of this Notebook:**\n",
    "\n",
    "1. Create a dataset for multivariate linear regression task\n",
    "2. Create our own Perceptron class from scratch\n",
    "3. Calculate the gradient descent from scratch\n",
    "4. Train our Perceptron\n",
    "5. Compare our Perceptron to the one prebuilt by PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb6d8e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28f4c9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start package installation...\n"
     ]
    }
   ],
   "source": [
    "print('Start package installation...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2581a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install torch\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b720743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Packages installed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9c74c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.14.0', '2.9.0+cu126')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from platform import python_version\n",
    "python_version(), torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60fc01fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leoyan/miniconda3/envs/idl/lib/python3.14/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:119.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09e72c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70aa3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):\n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj): setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5c5a2b",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2d8f47",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84443aec",
   "metadata": {},
   "source": [
    "The dataset $\\mathcal{D}$ is consists of the input data $\\mathbf{X}$ and\n",
    "the target data $\\mathbf{y}$\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\left\\{(\\mathbf{x}_{1}^{\\top}, y_{1}), \\cdots,\n",
    "(\\mathbf{x}_{m}^{\\top}, y_{m}) \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f71a28",
   "metadata": {},
   "source": [
    "The input data $\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$ can be represented as a matrix\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{X} &= \\begin{bmatrix}\n",
    "    x_{11} & \\cdots & x_{1n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & \\cdots & x_{mn}\n",
    "\\end{bmatrix} \\\\\n",
    "&= \\begin{bmatrix}\n",
    "    \\mathbf{x}_{1}^{\\top} \\\\\n",
    "    \\vdots \\\\\n",
    "    \\mathbf{x}_{m}^{\\top}\n",
    "\\end{bmatrix}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $m$ is the number of samples, $n$ is the number of *features*, and\n",
    "$\\mathbf{x}_{i}^{\\top} = \\begin{bmatrix} x_{i1} & \\cdots & x_{in} \\end{bmatrix} \\in \\mathbb{R}^{1 \\times n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd967630",
   "metadata": {},
   "source": [
    "The target data $\\mathbf{y} \\in \\mathbb{R}^{m}$ still without changes\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\begin{bmatrix}\n",
    "\ty_{1} \\\\ \\vdots \\\\ y_{m}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71190de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 4)\n",
      "(10100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import random\n",
    "\n",
    "\n",
    "M: int = 10_100 # number of samples\n",
    "N: int = 4 # number of features\n",
    "\n",
    "X, Y = make_regression(\n",
    "    n_samples=M, \n",
    "    n_features=N, \n",
    "    n_targets=1,\n",
    "    n_informative=N - 1, # let's add a features as a linear combination of others\n",
    "    bias=random.random(), # random true bias\n",
    "    noise=1\n",
    ")\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a092614",
   "metadata": {},
   "source": [
    "## split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31cf6fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 4]), torch.Size([100]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X[:100], device=device)\n",
    "Y_train = torch.tensor(Y[:100], device=device)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e9bbe9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 4]), torch.Size([10000]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = torch.tensor(X[100:], device=device)\n",
    "Y_test = torch.tensor(Y[100:], device=device)\n",
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd0f64",
   "metadata": {},
   "source": [
    "## delete raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b5e54ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b32cc0",
   "metadata": {},
   "source": [
    "# Scratch multivariate perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edf01e2",
   "metadata": {},
   "source": [
    "## weight and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef695bb",
   "metadata": {},
   "source": [
    "Our model $\\hat{\\mathbf{y}}(\\cdot)$ still have two trainable parameters $b, \\mathbf{w}$.\n",
    "But now note that weight is a vector\n",
    "\n",
    "$$\n",
    "\\mathbf{w} \\in \\mathbb{R}^{n}\n",
    "$$\n",
    "\n",
    "and $b \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c195005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLinearRegression:\n",
    "    def __init__(self, n_features: int):\n",
    "        self.b = torch.randn(1, device=device)\n",
    "        self.w = torch.randn(n_features, device=device)\n",
    "\n",
    "    def copy_params(self, torch_layer: nn.modules.linear.Linear):\n",
    "        \"\"\"\n",
    "        Copy the parameters from a module.linear to this model.\n",
    "\n",
    "        Args:\n",
    "            torch_layer: Pytorch module from which to copy the parameters.\n",
    "        \"\"\"\n",
    "        self.b.copy_(torch_layer.bias.detach().clone())\n",
    "        self.w.copy_(torch_layer.weight[0,:].detach().clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb746ec8",
   "metadata": {},
   "source": [
    "## weighted sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f194c3a7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\mathbf{y}}: \\mathbb{R}^{m \\times n} &\\to \\mathbb{R}^{m} \\\\\n",
    "\\mathbf{X} &\\mapsto \\hat{\\mathbf{y}}(\\mathbf{X}) = b + \\mathbf{Xw}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527436b",
   "metadata": {},
   "source": [
    "For one prediction\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{y}_{i} &= b + \\sum_{j=1}^{n} x_{ij} w_{j}\\\\\n",
    "&= b + \\mathbf{x}_{i}^{\\top} \\mathbf{w}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "this will be useful for gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79f44112",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultiLinearRegression)\n",
    "def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Predict the output for input x.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, n_features).\n",
    "\n",
    "    Returns:\n",
    "        y_pred: Predicted output tensor of shape (n_samples,).\n",
    "    \"\"\"\n",
    "    return torch.matmul(x, self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d76f5",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05aeed7",
   "metadata": {},
   "source": [
    "MSE still without changes.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L: \\mathbb{R}^{m} &\\to \\mathbb{R}^{+} \\\\\n",
    "\\hat{\\mathbf{y}} &\\mapsto L(\\hat{\\mathbf{y}}), \\;\n",
    "\\hat{\\mathbf{y}} \\in \\mathbb{R}^{m}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9abb1",
   "metadata": {},
   "source": [
    "$$\n",
    "L (\\hat{\\mathbf{y}}) = \n",
    "\\frac{1}{m} \\sum_{i=1}^{m} \\left(\n",
    "\t\\hat{y}_{i} - y_{i}\n",
    "\\right)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c6b077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultiLinearRegression)\n",
    "def mse_loss(self, y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "    \"\"\"\n",
    "    MSE loss function between target y_true and y_pred.\n",
    "\n",
    "    Args:\n",
    "        y_true: Target tensor of shape (n_samples,).\n",
    "        y_pred: Predicted tensor of shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "        loss: MSE loss between predictions and true values.\n",
    "    \"\"\"\n",
    "    return ((y_pred - y_true)**2).mean().item()\n",
    "\n",
    "@add_to_class(MultiLinearRegression)\n",
    "def evaluate(self, x: torch.Tensor, y_true: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Evaluate the model on input x and target y_true using MSE.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, n_features).\n",
    "        y_true: Target tensor of shape (n_samples,).\n",
    "\n",
    "    Returns:\n",
    "        loss: MSE loss between predictions and true values.\n",
    "    \"\"\"\n",
    "    y_pred = self.predict(x)\n",
    "    return self.mse_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a161ce",
   "metadata": {},
   "source": [
    "## gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c932e2c7",
   "metadata": {},
   "source": [
    "Let's follow the same strategy as before:\n",
    "\n",
    "+ First, determine the derivatives to be computed\n",
    "+ Then, ascertain the shape of each derivative\n",
    "+ Finally, compute the derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a063bc72",
   "metadata": {},
   "source": [
    "⭐️ We are using *Einstein notation*, that implies summation. For example\n",
    "\n",
    "$$\n",
    "a_{i} b_{i} \\equiv \\sum_{i} a_{i} b_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99c859",
   "metadata": {},
   "source": [
    "Derivative of MSE respect to bias\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} = \n",
    "\\frac{\\partial L}{\\partial \\hat{y}_{p}} \n",
    "\\frac{\\partial \\hat{y}_{p}}{\\partial b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2c5208",
   "metadata": {},
   "source": [
    "and derivative of MSE respect to weight\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{q}} = \n",
    "\\frac{\\partial L}{\\partial \\hat{y}_{p}} \n",
    "\\frac{\\partial \\hat{y}_{p}}{\\partial w_{q}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b4326",
   "metadata": {},
   "source": [
    "where the shape of each derivative is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b} \\in \\mathbb{R},\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} \\in \\mathbb{R}^{n},\n",
    "\\frac{\\partial L}{\\partial \\hat{\\mathbf{y}}} \\in \\mathbb{R}^{m},\n",
    "\\frac{\\partial \\hat{\\mathbf{y}}}{\\partial b} \\in \\mathbb{R}^{m},\n",
    "\\frac{\\partial \\hat{\\mathbf{y}}}{\\partial \\mathbf{w}} \\in \\mathbb{R}^{m \\times n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e1e3e",
   "metadata": {},
   "source": [
    "### MSE derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ca480",
   "metadata": {},
   "source": [
    "Derivative of MSE respect to predicted data is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial \\hat{y}_{p}} &= \n",
    "\\frac{\\partial}{\\partial \\hat{y}_{p}} \\left( \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\hat{y}_{i} - y_{i} \\right)^{2} \\right) \\\\\n",
    "&= \\frac{1}{m} \\sum_{i=1}^{m} \\frac{\\partial}{\\partial \\hat{y}_{p}} \\left( \\left( \\hat{y}_{i} - y_{i} \\right)^{2} \\right) \\\\\n",
    "&= \\frac{2}{m} \\sum_{i=1}^{m} \\left( \\hat{y}_{i} - y_{i} \\right) \\frac{\\partial \\hat{y}_{i}}{\\partial \\hat{y}_{p}} \\\\\n",
    "&= \\frac{2}{m} \\sum_{i=1}^{m} \\left( \\hat{y}_{i} - y_{i} \\right) \\delta_{ip} \\\\\n",
    "&=\\frac{2}{m} \\sum_{i=1}^{m} \\left[ \\hat{\\mathbf{y}} - \\mathbf{y} \\right]_{i} \\delta_{ip} \\\\\n",
    "&= \\frac{2}{m} \\left[ \\hat{\\mathbf{y}} - \\mathbf{y} \\right]_{p} \\\\\n",
    "&= \\frac{2}{m} \\left( \\hat{y}_{p} - y_{p} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "for $p = 1, \\ldots, m$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198225d",
   "metadata": {},
   "source": [
    "The vectorized form is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{\\mathbf{y}}} = \n",
    "\\frac{2}{m} \\left( \\hat{\\mathbf{y}} - \\mathbf{y} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85519660",
   "metadata": {},
   "source": [
    "### weighted sum derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866a76a",
   "metadata": {},
   "source": [
    "#### respect to bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c68f7e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\hat{y}_{p}}{\\partial b} &= \\frac{\\partial}{\\partial b} \\left( b + \\mathbf{x}_{p}^{\\top} \\mathbf{w} \\right) \\\\\n",
    "&= 1\n",
    "\\end{align}\n",
    "$$\n",
    "for $p = 1, \\ldots, m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98dba89",
   "metadata": {},
   "source": [
    "The vectorized form is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{\\mathbf{y}}}{\\partial b} = \\mathbf{1}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{1} \\in \\mathbb{R}^{m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72239d",
   "metadata": {},
   "source": [
    "#### respect to weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b693df",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\hat{y}_{p}}{\\partial w_{q}} &= \\frac{\\partial}{\\partial w_{q}} \\left( b + \\mathbf{x}_{p}^{\\top} \\mathbf{w} \\right) \\\\\n",
    "&= \\frac{\\partial}{\\partial w_{q}} \\left(\\mathbf{x}_{p}^{\\top} \\mathbf{w} \\right) \\\\\n",
    "&= \\frac{\\partial}{\\partial w_{q}} \\left( x_{p1}w_{1} + \\ldots + x_{pq}w_{q} + \\ldots + x_{pn}w_{n} \\right) \\\\\n",
    "&= \\frac{\\partial}{\\partial w_{q}} \\left( x_{pk} w_{k} \\right) \\\\\n",
    "&= x_{pk} \\delta_{kq} \\\\\n",
    "&= x_{pq}\n",
    "\\end{align}\n",
    "$$\n",
    "for $p = 1, \\ldots, m$, and $q = 1, \\ldots, n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1467d2",
   "metadata": {},
   "source": [
    "Vectoring for all $q = 1, \\ldots, n$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_{p}}{\\partial \\mathbf{w}} = \n",
    "\\mathbf{x}_{p}^{\\top} \\in \\mathbb{R}^{1 \\times n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576e0da",
   "metadata": {},
   "source": [
    "Vectorizing for all $p = 1, \\ldots, m$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{\\mathbf{y}}}{\\partial \\mathbf{w}} = \n",
    "\\mathbf{X} \\in \\mathbb{R}^{m \\times n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a1811",
   "metadata": {},
   "source": [
    "### full chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d94d1",
   "metadata": {},
   "source": [
    "Derivative of MSE respect to bias\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial b} &= \n",
    "{\\color{Cyan} \\frac{\\partial L}{\\partial \\hat{y}_{p}}}\n",
    "{\\color{Orange} \\frac{\\partial \\hat{y}_{p}}{\\partial b}} \\\\\n",
    "&= {\\color{Cyan} \\frac{2}{m} \\left( \\hat{y}_{p} - y_{p} \\right)}\n",
    "{\\color{Orange} 1_{p}} \\\\\n",
    "&= \\frac{2}{m} \\left< \\hat{\\mathbf{y}} - \\mathbf{y}, \\mathbf{1} \\right> \\\\\n",
    "&= \\frac{2}{m} \\left( \\hat{\\mathbf{y}} - \\mathbf{y} \\right)^{\\top} \\mathbf{1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67acf9db",
   "metadata": {},
   "source": [
    "Derivative of MSE respect to weight\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w_{q}} &= \n",
    "{\\color{Cyan} \\frac{\\partial L}{\\partial \\hat{y}_p}}\n",
    "{\\color{Magenta} \\frac{\\partial \\hat{y}_{p}}{\\partial w_{q}}} \\\\\n",
    "&= {\\color{Cyan} \\frac{2}{m} \\left(\\hat{y}_{p} - y_{p} \\right)} {\\color{Magenta} x_{pq}} \\\\\n",
    "&= \\frac{2}{m} \\left< \\hat{\\mathbf{y}} - \\mathbf{y}, \\mathbf{x}_{:,q} \\right> \\\\\n",
    "&= \\frac{2}{m} \\left( \\mathbf{x}_{:,q} \\right)^{\\top} \\left( \\hat{\\mathbf{y}} - \\mathbf{y} \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "for $q = 1, \\ldots, n$, where $\\mathbf{x}_{:,q} = \\begin{bmatrix} x_{1q} & \\cdots & x_{mq} \\end{bmatrix}^{\\top} \\in \\mathbb{R}^{m \\times 1}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0fb69e",
   "metadata": {},
   "source": [
    "Vectorized form is\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial \\mathbf{w}} &= \\frac{2}{m}\n",
    "\\mathbf{X}^{\\top} \\left( \\hat{\\mathbf{y}} - \\mathbf{y} \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1980fc89",
   "metadata": {},
   "source": [
    "### final gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6af363",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_{b}L = \n",
    "\\frac{2}{m} \\left( \\hat{\\mathbf{y}} - \\mathbf{y} \\right)^{\\top} \\mathbf{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7b1275",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_{\\mathbf{w}} L =\n",
    "\\frac{2}{m} \\mathbf{X}^{\\top} \\left( \\hat{\\mathbf{y}} - \\mathbf{y} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5c4ffe",
   "metadata": {},
   "source": [
    "## parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93f3c0",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "b &\\leftarrow b -\\eta \\nabla_{b}L \\\\ &=\n",
    "b -\\eta \\left(\n",
    "    \\frac{2}{m} (\\hat{\\mathbf{y}} - \\mathbf{y})^{\\top} \\mathbf{1}\n",
    "\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{w} &\\leftarrow \\mathbf{w} -\\eta \\nabla_{\\mathbf{w}}L \\\\ &=\n",
    "\\mathbf{w} -\\eta \\left(\n",
    "    \\frac{2}{m} \\mathbf{X}^{\\top} (\\hat{\\mathbf{y}} - \\mathbf{y}) \n",
    "\\right)\n",
    "\\end{align} \n",
    "$$\n",
    "\n",
    "where $\\eta \\in \\mathbb{R}^{+}$ is called *learning rate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1397b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultiLinearRegression)\n",
    "def update(self, x: torch.Tensor, y_true: torch.Tensor, \n",
    "           y_pred: torch.Tensor, lr: float):\n",
    "    \"\"\"\n",
    "    Update the model parameters.\n",
    "\n",
    "    Args:\n",
    "       x: Input tensor of shape (n_samples, n_features).\n",
    "       y_true: Target tensor of shape (n_samples,).\n",
    "       y_pred: Predicted output tensor of shape (n_samples,).\n",
    "       lr: Learning rate. \n",
    "    \"\"\"\n",
    "    delta = 2 * (y_pred - y_true) / len(y_true)\n",
    "    self.b -= lr * delta.sum()\n",
    "    self.w -= lr * torch.matmul(x.T, delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ea67a4",
   "metadata": {},
   "source": [
    "## gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4deeeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultiLinearRegression)\n",
    "def fit(self, x: torch.Tensor, y: torch.Tensor, \n",
    "        epochs: int, lr: float, batch_size: int, \n",
    "        x_valid: torch.Tensor, y_valid: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Fit the model using gradient descent.\n",
    "    \n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, n_features).\n",
    "        y: Target tensor of shape (n_samples,).\n",
    "        epochs: Number of epochs to fit.\n",
    "        lr: learning rate.\n",
    "        batch_size: Int number of batch.\n",
    "        x_valid: Input tensor of shape (n_valid_samples, n_features).\n",
    "        y_valid: Target tensor of shape (n_valid_samples,).\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        loss = []\n",
    "        for batch in range(0, len(y), batch_size):\n",
    "            end_batch = batch + batch_size\n",
    "\n",
    "            y_pred = self.predict(x[batch:end_batch])\n",
    "\n",
    "            loss.append(self.mse_loss(\n",
    "                y[batch:end_batch],\n",
    "                y_pred\n",
    "            ))\n",
    "\n",
    "            self.update(\n",
    "                x[batch:end_batch], \n",
    "                y[batch:end_batch], \n",
    "                y_pred, \n",
    "                lr\n",
    "            )\n",
    "\n",
    "        loss = round(sum(loss) / len(loss), 4)\n",
    "        loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "        print(f'epoch: {epoch} - MSE: {loss} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f14d2a",
   "metadata": {},
   "source": [
    "# Scrath vs Torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf00217b",
   "metadata": {},
   "source": [
    "## Torch.nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6e72aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchLinearRegression(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(TorchLinearRegression, self).__init__()\n",
    "        self.layer = nn.Linear(n_features, 1, device=device)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.forward(x)\n",
    "            return self.loss(y_pred, y).item()\n",
    "    \n",
    "    def fit(self, x, y, epochs, lr, batch_size, x_valid, y_valid):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            loss_t = [] # train loss\n",
    "            for batch in range(0, len(y), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "\n",
    "                y_pred = self.forward(x[batch:end_batch])\n",
    "                loss = self.loss(y_pred, y[batch:end_batch])\n",
    "                loss_t.append(loss.item())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            loss_t = round(sum(loss_t) / len(loss_t), 4)\n",
    "            loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "            print(f'epoch: {epoch} - MSE: {loss_t} - MSE_v: {loss_v}')\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "941be57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchLinearRegression(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4d5bf",
   "metadata": {},
   "source": [
    "## scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec97984d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLinearRegression(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20f1d76",
   "metadata": {},
   "source": [
    "## evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b62c79",
   "metadata": {},
   "source": [
    "We will use a *metric* to compare our model with the PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af786c4",
   "metadata": {},
   "source": [
    "### import MAPE modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e999304f",
   "metadata": {},
   "source": [
    "We will use a modification of *MAPE* as a metric\n",
    "\n",
    "$$\n",
    "\\text{MAPE}(\\mathbf{y}, \\hat{\\mathbf{y}}) =\n",
    "\\frac{1}{m} \\sum^{m}_{i=1} \\mathcal{L} (y_{i}, \\hat{y}_{i})\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathcal{L} (y_{i}, \\hat{y}_{i}) = \\begin{cases}\n",
    "    \\left| \\frac{y_{i} - \\hat{y}_{i}}{y_{i}} \\right|\n",
    "    & \\text{if } y_{i} \\neq 0 \\\\\n",
    "    \\left| \\hat{y}_{i} \\right| & \\text{if } \\hat{y}_{i} = 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9960ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mape imported locally.\n"
     ]
    }
   ],
   "source": [
    "# This cell imports torch_mape \n",
    "# if you are running this notebook locally \n",
    "# or from Google Colab.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "try:\n",
    "    from tools.torch_metrics import torch_mape as mape\n",
    "    print('mape imported locally.')\n",
    "except ModuleNotFoundError:\n",
    "    import subprocess\n",
    "\n",
    "    repo_url = 'https://raw.githubusercontent.com/PilotLeoYan/inside-deep-learning/main/content/tools/torch_metrics.py'\n",
    "    local_file = 'torch_metrics.py'\n",
    "    \n",
    "    subprocess.run(['wget', repo_url, '-O', local_file], check=True)\n",
    "    try:\n",
    "        from torch_metrics import torch_mape as mape # type: ignore\n",
    "        print('mape imported from GitHub.')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2a07f",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76dc625",
   "metadata": {},
   "source": [
    "Let's compare the predictions of our model and PyTorch's using modified MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c330baa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.432626662762388"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_test),\n",
    "    torch_model.forward(X_test).squeeze(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290b3acc",
   "metadata": {},
   "source": [
    "They differ considerably because each model has its own parameters \n",
    "initialized randomly and independently of the other model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11f9a9",
   "metadata": {},
   "source": [
    "### copy parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f5beab",
   "metadata": {},
   "source": [
    "We copy the values of the PyTorch model parameters to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "792e3f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.copy_params(torch_model.layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8267733",
   "metadata": {},
   "source": [
    "### predictions after copy parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b56027",
   "metadata": {},
   "source": [
    "We measure the difference between the predictions of both models again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3156a407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_test),\n",
    "    torch_model.forward(X_test).squeeze(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b410ce9",
   "metadata": {},
   "source": [
    "We can see that their predictions do not differ greatly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75291f08",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e1bdb4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.evaluate(X_test, Y_test),\n",
    "    torch_model.evaluate(X_test, Y_test.unsqueeze(-1))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca90ca0c",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f472f8b",
   "metadata": {},
   "source": [
    "We are going to train both models using the same hyperparameters' value. \n",
    "If our model is well designed, then starting from the same parameters \n",
    "it should arrive at the same parameters' values as the PyTorch model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31bf43cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR: float = 0.01 # learning rate\n",
    "EPOCHS: int = 16 # number of epochs\n",
    "BATCH: int = len(X_train) // 3 # number of minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9632adb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 3701.5284 - MSE_v: 3197.1711\n",
      "epoch: 1 - MSE: 2913.2982 - MSE_v: 2740.885\n",
      "epoch: 2 - MSE: 2324.5076 - MSE_v: 2376.62\n",
      "epoch: 3 - MSE: 1881.3441 - MSE_v: 2081.6647\n",
      "epoch: 4 - MSE: 1544.8211 - MSE_v: 1839.3778\n",
      "epoch: 5 - MSE: 1286.6667 - MSE_v: 1637.5224\n",
      "epoch: 6 - MSE: 1086.3535 - MSE_v: 1467.0603\n",
      "epoch: 7 - MSE: 928.9557 - MSE_v: 1321.2811\n",
      "epoch: 8 - MSE: 803.5995 - MSE_v: 1195.1708\n",
      "epoch: 9 - MSE: 702.3454 - MSE_v: 1084.955\n",
      "epoch: 10 - MSE: 619.3794 - MSE_v: 987.7678\n",
      "epoch: 11 - MSE: 550.4292 - MSE_v: 901.4109\n",
      "epoch: 12 - MSE: 492.3422 - MSE_v: 824.1796\n",
      "epoch: 13 - MSE: 442.7796 - MSE_v: 754.7352\n",
      "epoch: 14 - MSE: 399.9957 - MSE_v: 692.0129\n",
      "epoch: 15 - MSE: 362.6781 - MSE_v: 635.1533\n"
     ]
    }
   ],
   "source": [
    "torch_model.fit(\n",
    "    X_train, \n",
    "    Y_train.unsqueeze(-1),\n",
    "    EPOCHS, LR, BATCH,\n",
    "    X_test,\n",
    "    Y_test.unsqueeze(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f3aab8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 3701.5284 - MSE_v: 3197.1711\n",
      "epoch: 1 - MSE: 2913.2982 - MSE_v: 2740.885\n",
      "epoch: 2 - MSE: 2324.5076 - MSE_v: 2376.62\n",
      "epoch: 3 - MSE: 1881.3441 - MSE_v: 2081.6647\n",
      "epoch: 4 - MSE: 1544.8211 - MSE_v: 1839.3778\n",
      "epoch: 5 - MSE: 1286.6667 - MSE_v: 1637.5224\n",
      "epoch: 6 - MSE: 1086.3535 - MSE_v: 1467.0603\n",
      "epoch: 7 - MSE: 928.9557 - MSE_v: 1321.2811\n",
      "epoch: 8 - MSE: 803.5995 - MSE_v: 1195.1708\n",
      "epoch: 9 - MSE: 702.3454 - MSE_v: 1084.955\n",
      "epoch: 10 - MSE: 619.3794 - MSE_v: 987.7678\n",
      "epoch: 11 - MSE: 550.4292 - MSE_v: 901.4109\n",
      "epoch: 12 - MSE: 492.3422 - MSE_v: 824.1796\n",
      "epoch: 13 - MSE: 442.7796 - MSE_v: 754.7352\n",
      "epoch: 14 - MSE: 399.9957 - MSE_v: 692.0129\n",
      "epoch: 15 - MSE: 362.6781 - MSE_v: 635.1533\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train,\n",
    "    EPOCHS, LR, BATCH,\n",
    "    X_test, Y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a5974b",
   "metadata": {},
   "source": [
    "### predictions after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0080336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4907112647892055e-16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_test),\n",
    "    torch_model.forward(X_test).squeeze(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bee3c5",
   "metadata": {},
   "source": [
    "### bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea73376",
   "metadata": {},
   "source": [
    "We directly measure the difference between the bias values of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d33f3342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9354088981671021e-16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.b.clone(),\n",
    "    torch_model.layer.bias.detach()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94d4d6",
   "metadata": {},
   "source": [
    "### weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab10b9",
   "metadata": {},
   "source": [
    "And measure the difference between the weight values of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d0c97fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.w.clone(),\n",
    "    torch_model.layer.weight.detach().squeeze(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e83a86e",
   "metadata": {},
   "source": [
    "All right, our implementation is correct respect to PyTorch. \n",
    "Now, we can finally tackle Multioutput in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
