{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 - Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{grid} 1 1 2 2\n",
    "```{card} [Open in Google Colab](https://colab.research.google.com/github/PilotLeoYan/inside-deep-learning/blob/main/content/1-linear-regression/1-34-weight-decay.ipynb)\n",
    "```{image} ../figures/colab_logo.png\n",
    ":align: center\n",
    "```\n",
    "```{card} [Open in Jupyter NBViewer](https://nbviewer.org/github/PilotLeoYan/inside-deep-learning/blob/main/content/1-linear-regression/1-4-weight-decay.ipynb)\n",
    "```{image} ../figures/jupyter_logo.png\n",
    ":align: center\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue from multioutput linear regression. \n",
    "Now let's incorporate the $\\ell_2$ regularization ($L_{2}$) into our model.\n",
    "$\\ell_2$ regularization is a technique that prevents models from overfitting \n",
    "by penalizing large weight values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose of this Notebook**:\n",
    "\n",
    "1. Create a dataset\n",
    "2. Incorporate $\\ell_2$ regularization into our Perceptron from scratch\n",
    "3. Train our Perceptron\n",
    "4. Compare our Perceptron to the one prebuilt by PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš¨ This notebook is a copy of [1.3 - Multioutput Linear Regression](./1-3-multioutput-linear-regression.ipynb).\n",
    "Only modified parameters update, the rest is unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start package installation...\n"
     ]
    }
   ],
   "source": [
    "print('Start package installation...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install torch\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Packages installed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.14.0', '2.9.0+cu126')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from platform import python_version\n",
    "python_version(), torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):  \n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj): setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{X} &\\in \\mathbb{R}^{m \\times n} \\\\\n",
    "\\mathbf{Y} &\\in \\mathbb{R}^{m \\times n_{o}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 6)\n",
      "(10100, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import random\n",
    "\n",
    "M: int = 10_100 # number of samples\n",
    "N: int = 6 # number of input features\n",
    "NO: int = 3 # number of output features\n",
    "\n",
    "X, Y = make_regression(\n",
    "    n_samples=M, \n",
    "    n_features=N, \n",
    "    n_targets=NO, \n",
    "    n_informative=N - 1,\n",
    "    bias=random.random(),\n",
    "    noise=1\n",
    ")\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 6]), torch.Size([100, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X[:100], device=device)\n",
    "Y_train = torch.tensor(Y[:100], device=device)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 6]), torch.Size([10000, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = torch.tensor(X[100:], device=device)\n",
    "Y_valid = torch.tensor(Y[100:], device=device)\n",
    "X_valid.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing we are going to modify is the way in which the model weights are updated. \n",
    "The rest, such as parameter initialization and model training remain unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, n_features: int, out_features: int, lambd: float):\n",
    "        self.w = torch.randn(n_features, out_features, device=device)\n",
    "        self.b = torch.randn(out_features, device=device)\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def copy_params(self, torch_layer: torch.nn.modules.linear.Linear):\n",
    "        \"\"\"\n",
    "        Copy the parameters from a module.linear to this model.\n",
    "\n",
    "        Args:\n",
    "            torch_layer: Pytorch module from which to copy the parameters.\n",
    "        \"\"\"\n",
    "        self.b.copy_(torch_layer.bias.detach().clone())\n",
    "        self.w.copy_(torch_layer.weight.T.detach().clone())\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict the output for input x\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            y_pred: Predicted output tensor of shape (n_samples, out_features).\n",
    "        \"\"\"\n",
    "        return torch.matmul(x, self.w) + self.b\n",
    "\n",
    "    def mse_loss(self, y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "        \"\"\"\n",
    "        MSE loss function between target y_true and y_pred.\n",
    "\n",
    "        Args:\n",
    "            y_true: Target tensor of shape (n_samples, out_features).\n",
    "            y_pred: Predicted tensor of shape (n_samples, out_features).\n",
    "\n",
    "        Returns:\n",
    "            loss: MSE loss between predictions and true values.\n",
    "        \"\"\"\n",
    "        return ((y_pred - y_true)**2).mean().item()\n",
    "\n",
    "    def evaluate(self, x: torch.Tensor, y_true: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Evaluate the model on input x and target y_true using MSE.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (n_samples, n_features).\n",
    "            y_true: Target tensor of shape (n_samples, out_features).\n",
    "\n",
    "        Returns:\n",
    "            loss: MSE loss between predictions and true values.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        return self.mse_loss(y_true, y_pred)\n",
    "\n",
    "    def fit(self, x_train: torch.Tensor, y_train: torch.Tensor, \n",
    "        epochs: int, lr: float, batch_size: int, \n",
    "        x_valid: torch.Tensor, y_valid: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Fit the model using gradient descent.\n",
    "        \n",
    "        Args:\n",
    "            x_train: Input tensor of shape (n_samples, n_features).\n",
    "            y_train: Target tensor of shape (n_samples, out_features).\n",
    "            epochs: Number of epochs to fit.\n",
    "            lr: learning rate.\n",
    "            batch_size: Int number of batch.\n",
    "            x_valid: Input tensor of shape (n_valid_samples, n_features).\n",
    "            y_valid: Target tensor of shape (n_valid_samples, out_features)\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            loss = []\n",
    "            for batch in range(0, len(y_train), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "\n",
    "                y_pred = self.predict(x_train[batch:end_batch])\n",
    "\n",
    "                loss.append(self.mse_loss(\n",
    "                    y_train[batch:end_batch], \n",
    "                    y_pred\n",
    "                ))\n",
    "\n",
    "                self.update(\n",
    "                    x_train[batch:end_batch], \n",
    "                    y_train[batch:end_batch], \n",
    "                    y_pred, \n",
    "                    lr\n",
    "                )\n",
    "\n",
    "            loss = round(sum(loss) / len(loss), 4)\n",
    "            loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "            print(f'epoch: {epoch} - MSE: {loss} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of training the model with the loss function $L$, \n",
    "we are going to use the objective function $J$. \n",
    "Typically our objective function is as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\hat{\\mathbf{Y}}, \\mathbf{\\theta}) = \n",
    "L(\\hat{\\mathbf{Y}}) + \\text{regularization}(\\theta)\n",
    "$$\n",
    "where $\\mathbf{\\theta}$ is an arbitrary parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Do not use the objective function to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a weight decay technique, we will $\\ell_2$ or $L_{2}$\n",
    "\n",
    "$$\n",
    "\\ell_2(\\mathbf{\\theta}) = \n",
    "\\frac{\\lambda}{2} \\left\\| \\mathbf{\\theta} \\right\\|^{2}_{2}\n",
    "$$\n",
    "\n",
    "where commonly $\\mathbf{\\theta} \\in \\mathbb{R}^{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸš¨ Tecnically, weight decay and $\\ell_{2}$ are different in a special scenarios,\n",
    "but for standard GD (gradient descent) they are mathematically equivalent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: $\\lambda \\in \\mathbb{R}$ is as a *hyperparameter*, \n",
    "because it is a parameter set by the developer (you) not by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we have $\\mathbf{W} \\in \\mathbb{R}^{n \\times n_{o}}$, then we need to do an equivalence operation.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\ell_2(\\mathbf{W}) &= \\frac{\\lambda}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n_{o}} w_{ij}^{2} \\\\\n",
    "&= \\frac{\\lambda}{2} \\text{sum} \\left( \\mathbf{W}^{2} \\right) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where ${\\mathbf{A}}^2$ is element-wise power ${\\mathbf{A}}^2 = \\mathbf{A} \\odot \\mathbf{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Typically, weight decay only affects the weight, but the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objective function derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J}{\\partial w_{rs}} =\n",
    "\\frac{\\partial L}{\\partial w_{rs}} +\n",
    "\\frac{\\partial \\ell_2}{\\partial w_{rs}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell_2}{\\partial w_{rs}} &=\n",
    "\\frac{\\lambda}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n_{o}}\n",
    "\\frac{\\partial}{\\partial w_{rs}} \\left( \n",
    "    w_{ij}^{2}\n",
    "\\right) \\\\\n",
    "&= \\lambda \\sum_{i=1}^{n} \\sum_{j=1}^{n_{o}} w_{ij} \n",
    "\\frac{\\partial w_{ij}}{\\partial w_{rs}} \\\\\n",
    "&= \\lambda \\sum_{i=1}^{n} \\sum_{j=1}^{n_{o}} w_{ij} \n",
    "\\delta_{ir} \\delta_{js} \\\\\n",
    "&= \\lambda \\sum_{i=1}^{n} w_{rj} \\delta_{js} \\\\\n",
    "&= \\lambda w_{rs}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "for $r = 1, \\ldots, n$, and $s = 1, \\ldots, n_{o}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorzied form\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\ell_2}{\\partial \\mathbf{W}} =\n",
    "\\lambda \\mathbf{W}\n",
    "$$\n",
    "\n",
    "**Remark**: $\\nabla_{\\mathbf{W}}\\ell_2 \\in \\mathbb{R}^{n \\times n_{o}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial J}{\\partial \\mathbf{W}} &=\n",
    "{\\color{Orange} {\\frac{\\partial L}{\\partial \\mathbf{W}}}} +\n",
    "{\\color{Cyan} {\\frac{\\partial \\ell_2}{\\partial \\mathbf{W}}}} \\\\\n",
    "&= {\\color{Orange} {\\nabla_{\\mathbf{W}}L}} + \n",
    "{\\color{Cyan} {\\lambda \\mathbf{W}}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(LinearRegression)\n",
    "def update(self, x: torch.Tensor, y_true: torch.Tensor, y_pred: torch.Tensor, lr: float):\n",
    "    \"\"\"\n",
    "    Update the model parameters with L2 regularization.\n",
    "\n",
    "    Args:\n",
    "       x: Input tensor of shape (n_samples, n_features).\n",
    "       y_true: Target tensor of shape (n_samples, out_features).\n",
    "       y_pred: Predicted output tensor of shape (n_samples, out_features).\n",
    "       lr: Learning rate. \n",
    "    \"\"\"\n",
    "    delta = 2 * (y_pred - y_true) / y_true.numel()\n",
    "    self.b -= lr * delta.sum(axis=0)\n",
    "    self.w -= lr * (torch.matmul(x.T, delta) + self.lambd * self.w) # L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch vs Torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchLinearRegression(nn.Module):\n",
    "    def __init__(self, n_features, n_out_features):\n",
    "        super(TorchLinearRegression, self).__init__()\n",
    "        self.layer = nn.Linear(n_features, n_out_features, device=device)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.forward(x)\n",
    "            return self.loss(y_pred, y).item()\n",
    "    \n",
    "    def fit(self, x, y, epochs, lr, batch_size, x_valid, y_valid, weight_decay):\n",
    "        optimizer = torch.optim.SGD([\n",
    "            {'params': self.layer.weight, 'weight_decay': weight_decay},\n",
    "            {'params': self.layer.bias} # it is important to specify the weight decay for the bias.\n",
    "        ], lr=lr)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss_t = []\n",
    "            for batch in range(0, len(y), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "\n",
    "                y_pred = self.forward(x[batch:end_batch])\n",
    "                loss = self.loss(y_pred, y[batch:end_batch])\n",
    "                loss_t.append(loss.item())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            loss_t = round(sum(loss_t) / len(loss_t), 4)\n",
    "            loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "            print(f'epoch: {epoch} - MSE: {loss_t} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchLinearRegression(N, NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAMBD: float = 0.01\n",
    "\n",
    "model = LinearRegression(N, NO, LAMBD)\n",
    "model.lambd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import MAPE modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mape imported locally.\n"
     ]
    }
   ],
   "source": [
    "# This cell imports torch_mape \n",
    "# if you are running this notebook locally \n",
    "# or from Google Colab.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "try:\n",
    "    from tools.torch_metrics import torch_mape as mape\n",
    "    print('mape imported locally.')\n",
    "except ModuleNotFoundError:\n",
    "    import subprocess\n",
    "\n",
    "    repo_url = 'https://raw.githubusercontent.com/PilotLeoYan/inside-deep-learning/main/content/tools/torch_metrics.py'\n",
    "    local_file = 'torch_metrics.py'\n",
    "    \n",
    "    subprocess.run(['wget', repo_url, '-O', local_file], check=True)\n",
    "    try:\n",
    "        from torch_metrics import torch_mape as mape # type: ignore\n",
    "        print('mape imported from GitHub.')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.467373863210437"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.copy_params(torch_model.layer)\n",
    "parameters = (model.b.clone(), model.w.clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction after copy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.evaluate(X_valid, Y_valid),\n",
    "    torch_model.evaluate(X_valid, Y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR: float = 0.01 # learning rate\n",
    "EPOCHS: int = 16 # number of epochs\n",
    "BATCH: int = len(X_train) // 3 # batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 17229.942 - MSE_v: 15194.1599\n",
      "epoch: 1 - MSE: 15961.8323 - MSE_v: 14354.9617\n",
      "epoch: 2 - MSE: 14807.8438 - MSE_v: 13576.873\n",
      "epoch: 3 - MSE: 13756.6005 - MSE_v: 12854.434\n",
      "epoch: 4 - MSE: 12797.9107 - MSE_v: 12182.7278\n",
      "epoch: 5 - MSE: 11922.6417 - MSE_v: 11557.3237\n",
      "epoch: 6 - MSE: 11122.6077 - MSE_v: 10974.2271\n",
      "epoch: 7 - MSE: 10390.4696 - MSE_v: 10429.8336\n",
      "epoch: 8 - MSE: 9719.6455 - MSE_v: 9920.8896\n",
      "epoch: 9 - MSE: 9104.2311 - MSE_v: 9444.4553\n",
      "epoch: 10 - MSE: 8538.9276 - MSE_v: 8997.8729\n",
      "epoch: 11 - MSE: 8018.9786 - MSE_v: 8578.7376\n",
      "epoch: 12 - MSE: 7540.1128 - MSE_v: 8184.8715\n",
      "epoch: 13 - MSE: 7098.4929 - MSE_v: 7814.301\n",
      "epoch: 14 - MSE: 6690.6702 - MSE_v: 7465.2356\n",
      "epoch: 15 - MSE: 6313.5439 - MSE_v: 7136.0495\n"
     ]
    }
   ],
   "source": [
    "torch_model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH, \n",
    "    X_valid, Y_valid,\n",
    "    LAMBD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 17229.942 - MSE_v: 15194.1599\n",
      "epoch: 1 - MSE: 15961.8323 - MSE_v: 14354.9617\n",
      "epoch: 2 - MSE: 14807.8438 - MSE_v: 13576.873\n",
      "epoch: 3 - MSE: 13756.6005 - MSE_v: 12854.434\n",
      "epoch: 4 - MSE: 12797.9107 - MSE_v: 12182.7278\n",
      "epoch: 5 - MSE: 11922.6417 - MSE_v: 11557.3237\n",
      "epoch: 6 - MSE: 11122.6077 - MSE_v: 10974.2271\n",
      "epoch: 7 - MSE: 10390.4696 - MSE_v: 10429.8336\n",
      "epoch: 8 - MSE: 9719.6455 - MSE_v: 9920.8896\n",
      "epoch: 9 - MSE: 9104.2311 - MSE_v: 9444.4553\n",
      "epoch: 10 - MSE: 8538.9276 - MSE_v: 8997.8729\n",
      "epoch: 11 - MSE: 8018.9786 - MSE_v: 8578.7376\n",
      "epoch: 12 - MSE: 7540.1128 - MSE_v: 8184.8715\n",
      "epoch: 13 - MSE: 7098.4929 - MSE_v: 7814.301\n",
      "epoch: 14 - MSE: 6690.6702 - MSE_v: 7465.2356\n",
      "epoch: 15 - MSE: 6313.5439 - MSE_v: 7136.0495\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH, \n",
    "    X_valid, Y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.406488218320351e-16"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.b.clone(),\n",
    "    torch_model.layer.bias.detach()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0475895519114729e-16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.w.clone(),\n",
    "    torch_model.layer.weight.detach().T\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
