{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "224188c7",
   "metadata": {},
   "source": [
    "# 1.3 - Multioutput Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f83e2e4",
   "metadata": {},
   "source": [
    ":::{grid} 1 1 2 2\n",
    "```{card} [Open in Google Colab](https://colab.research.google.com/github/PilotLeoYan/inside-deep-learning/blob/main/content/1-linear-regression/1-3-multioutput-linear-regression.ipynb)\n",
    "```{image} ../figures/colab_logo.png\n",
    ":align: center\n",
    "```\n",
    "```{card} [Open in Jupyter NBViewer](https://nbviewer.org/github/PilotLeoYan/inside-deep-learning/blob/main/content/1-linear-regression/1-3-multioutput-linear-regression.ipynb)\n",
    "```{image} ../figures/jupyter_logo.png\n",
    ":align: center\n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61de88c",
   "metadata": {},
   "source": [
    "Now we are going to increase the complexity, \n",
    "instead of the perceptron have a single output, \n",
    "it will have multiple outputs. Multioutput perceptron\n",
    "will allow us to create Classification for the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc57e41",
   "metadata": {},
   "source": [
    "```{image} ../figures/multioutput-perceptron.png\n",
    ":width: 300\n",
    ":class: hidden dark:block\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39007d01",
   "metadata": {},
   "source": [
    "```{image} ../figures/multioutput-perceptron-light.png\n",
    ":width: 300\n",
    ":class: dark:hidden\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7789bd",
   "metadata": {},
   "source": [
    "We can think multioutput perceptron as a layer of several multivariate perceptrons,\n",
    "and each perceptron output corresponds to an *output feature*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bbb50c",
   "metadata": {},
   "source": [
    "```{image} ../figures/multioutput-perceptron-as-layer.png\n",
    ":width: 300\n",
    ":class: hidden dark:block\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f5af5d",
   "metadata": {},
   "source": [
    "```{image} ../figures/multioutput-perceptron-as-layer-light.png\n",
    ":width: 300\n",
    ":class: dark:hidden\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb7224",
   "metadata": {},
   "source": [
    "The goal of multioutput perceptron is estimate $f(\\cdot)$ by a \n",
    "linear approximation $\\hat{f}(\\cdot)$ such that\n",
    "\n",
    "$$\n",
    "\\mathbf{Y} = \\hat{f}(\\mathbf{X}) + \\epsilon\n",
    "$$\n",
    "\n",
    "Note that the target $\\mathbf{Y}$ is now a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403f8328",
   "metadata": {},
   "source": [
    "**Purpose of this Notebook**:\n",
    "\n",
    "1. Create a dataset for multioutput linear regression task\n",
    "2. Create our own Multioutput Perceptron class from scratch\n",
    "3. Calculate the gradient descent from scratch\n",
    "4. Train our Perceptron\n",
    "5. Compare our Perceptron to the one prebuilt by PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daff8a0c",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6147b534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start package installation...\n"
     ]
    }
   ],
   "source": [
    "print('Start package installation...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa60aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install torch\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a8f1705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "print('Packages installed successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "994844c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.14.0', '2.9.0+cu126')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from platform import python_version\n",
    "python_version(), torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40bf84f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed193c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "423cbad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):  \n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj): setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e26a6",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f856727",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bd3f6a",
   "metadata": {},
   "source": [
    "The dataset $\\mathcal{D}$ is consists of the input data\n",
    "$\\mathbf{X}$ and the target data $\\mathbf{Y}$\n",
    "\n",
    "$$\n",
    "\\mathcal{D} = \\left\\{ (\\mathbf{x}^{\\top}_{1}, \\mathbf{y}^{\\top}_{1}),\n",
    "\\cdots, (\\mathbf{x}^{\\top}_{m}, \\mathbf{y}^{\\top}_{m}) \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93acc609",
   "metadata": {},
   "source": [
    "The input data $\\mathbf{X} \\in \\mathbb{R}^{m \\times n}$ can be represented as a matrix\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "    x_{11} & \\cdots & x_{1n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & \\cdots & x_{mn}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $m$ is the number of samples, and $n$ is the number of *input features*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1c4a9e",
   "metadata": {},
   "source": [
    "The target data $\\mathbf{Y} \\in \\mathbb{R}^{m \\times n_{o}}$\n",
    "\n",
    "$$\n",
    "\\mathbf{Y} = \\begin{bmatrix}\n",
    "    y_{11} & \\cdots & y_{1n_{o}} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    y_{m1} & \\cdots & y_{m n_{o}}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $n_{o}$ is the number of *output features*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fd796ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 6)\n",
      "(10100, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import random\n",
    "\n",
    "M: int = 10_100 # number of samples\n",
    "N: int = 6 # number of input features\n",
    "NO: int = 3 # number of output features\n",
    "\n",
    "X, Y = make_regression(\n",
    "    n_samples=M, \n",
    "    n_features=N, \n",
    "    n_targets=NO, \n",
    "    n_informative=N - 1,\n",
    "    bias=random.random(),\n",
    "    noise=1\n",
    ")\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3b0ae",
   "metadata": {},
   "source": [
    "## split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "843952c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 6]), torch.Size([100, 3]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X[:100], device=device)\n",
    "Y_train = torch.tensor(Y[:100], device=device)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecd19710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 6]), torch.Size([10000, 3]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = torch.tensor(X[100:], device=device)\n",
    "Y_valid = torch.tensor(Y[100:], device=device)\n",
    "X_valid.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4956283",
   "metadata": {},
   "source": [
    "## delete raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d88b35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfdb04d",
   "metadata": {},
   "source": [
    "# Scratch multiout perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516ddf5",
   "metadata": {},
   "source": [
    "## weight and bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3617f606",
   "metadata": {},
   "source": [
    "Our model $\\hat{\\mathbf{Y}}(\\cdot)$ have two trainable parameters\n",
    "$\\mathbf{b, W}$ called bias and weight respectively\n",
    "\n",
    "$$\n",
    "\\mathbf{b} \\in \\mathbb{R}^{n_{o}} \\\\\n",
    "\\mathbf{W} \\in \\mathbb{R}^{n \\times n_{o}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1970ec08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultioutputRegression:\n",
    "    def __init__(self, n_features: int, out_features: int):\n",
    "        self.b = torch.randn(out_features, device=device)\n",
    "        self.w = torch.randn(n_features, out_features, device=device)\n",
    "\n",
    "    def copy_params(self, torch_layer: torch.nn.modules.linear.Linear):\n",
    "        \"\"\"\n",
    "        Copy the parameters from a module.linear to this model.\n",
    "\n",
    "        Args:\n",
    "            torch_layer: Pytorch module from which to copy the parameters.\n",
    "        \"\"\"\n",
    "        self.b.copy_(torch_layer.bias.detach().clone())\n",
    "        self.w.copy_(torch_layer.weight.T.detach().clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51145137",
   "metadata": {},
   "source": [
    "## weighted sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b333ef4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\mathbf{Y}}: \\mathbb{R}^{m \\times n} &\\to \\mathbb{R}^{m \\times n_{o}} \\\\\n",
    "\\mathbf{X} &\\mapsto \\hat{\\mathbf{Y}} \\mathbf{(X) = b + XW}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fbc1f2",
   "metadata": {},
   "source": [
    "**Remark**: We cann add a vector $\\mathbf{b}$ to a matrix $\\mathbf{XW}$ due to broadcasting mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999cfbb9",
   "metadata": {},
   "source": [
    "For one prediction in the $i$-th sample at the $j$-th output feature\n",
    "\n",
    "$$\n",
    "\\hat{y}_{ij} = b_{j} + \\sum_{k=1}^{n} x_{ik} w_{kj}\n",
    "$$\n",
    "\n",
    "for $i = 1, \\ldots, m$, and $j = 1, \\ldots, n_{o}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "744a8849",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultioutputRegression)\n",
    "def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Predict the output for input x\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, n_features).\n",
    "\n",
    "    Returns:\n",
    "        y_pred: Predicted output tensor of shape (n_samples, out_features).\n",
    "    \"\"\"\n",
    "    return torch.matmul(x, self.w) + self.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84af6a9e",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44716ad1",
   "metadata": {},
   "source": [
    "MSE is now defined as \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "L: \\mathbb{R}^{m \\times n_{o}} &\\to \\mathbb{R}^{+} \\\\\n",
    "\\hat{\\mathbf{Y}} &\\mapsto L(\\hat{\\mathbf{Y}}), \\hat{\\mathbf{Y}} \\in \\mathbb{R}^{m \\times n_{o}}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2621486",
   "metadata": {},
   "source": [
    "$$\n",
    "L(\\hat{\\mathbf{Y}}) = \\frac{1}{m n_{o}} \\sum_{i=1}^{m} \\sum_{j=1}^{n_{o}}\n",
    "\\left( \\hat{y}_{ij} - y_{ij} \\right)^{2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36f6101",
   "metadata": {},
   "source": [
    "Vectorized form\n",
    "\n",
    "$$\n",
    "L(\\hat{\\mathbf{Y}}) = \\frac{1}{m n_{o}} \\text{sum}\n",
    "\\left( \\left( \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right)^{2} \\right)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{A}^{2}$ is element-wise power $\\mathbf{A}^{2} = \\mathbf{A \\odot A}$.\n",
    "\n",
    "**Note**: $\\odot$ is called Hadamard product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16fe7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultioutputRegression)\n",
    "def mse_loss(self, y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "    \"\"\"\n",
    "    MSE loss function between target y_true and y_pred.\n",
    "\n",
    "    Args:\n",
    "        y_true: Target tensor of shape (n_samples, out_features).\n",
    "        y_pred: Predicted tensor of shape (n_samples, out_features).\n",
    "\n",
    "    Returns:\n",
    "        loss: MSE loss between predictions and true values.\n",
    "    \"\"\"\n",
    "    return ((y_pred - y_true)**2).mean().item()\n",
    "\n",
    "@add_to_class(MultioutputRegression)\n",
    "def evaluate(self, x: torch.Tensor, y_true: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Evaluate the model on input x and target y_true using MSE.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of shape (n_samples, n_features).\n",
    "        y_true: Target tensor of shape (n_samples, out_features).\n",
    "\n",
    "    Returns:\n",
    "        loss: MSE loss between predictions and true values.\n",
    "    \"\"\"\n",
    "    y_pred = self.predict(x)\n",
    "    return self.mse_loss(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6073bc0",
   "metadata": {},
   "source": [
    "## gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e04433",
   "metadata": {},
   "source": [
    "Let's follow the same strategy as before:\n",
    "\n",
    "+ First, determine the derivatives to be computed\n",
    "+ Then, ascertain the shape of each derivative\n",
    "+ Finally, compute the derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f832dd",
   "metadata": {},
   "source": [
    "⭐️ We are using *Einstein notation*, that implies summation\n",
    "\n",
    "$$\n",
    "a_{i} b_{i} \\equiv \\sum_{i} a_{i} b_{i}\n",
    "$$\n",
    "\n",
    "we will use Einstein notation for chain rule summation, for example\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial g_{i}} \\frac{\\partial g_{i}}{\\partial x}\n",
    "\\equiv \\sum_{i} \\frac{\\partial f}{\\partial g_{i}} \\frac{\\partial g_{i}}{\\partial x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b2c14",
   "metadata": {},
   "source": [
    "Derivative of MSE respect to bias\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial b_{r}} = \n",
    "\\frac{\\partial L}{\\partial \\hat{y}_{pq}}\n",
    "\\frac{\\partial \\hat{y}_{pq}}{\\partial b_{r}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e763b",
   "metadata": {},
   "source": [
    "and derivative of MSE respect to weight\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial w_{rs}} =\n",
    "\\frac{\\partial L}{\\partial \\hat{y}_{pq}}\n",
    "\\frac{\\partial \\hat{y}_{pq}}{\\partial w_{rs}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ea82c",
   "metadata": {},
   "source": [
    "where the shape of each derivative is\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{b}} \\in \\mathbb{R}^{n_{o}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{W}} \\in \\mathbb{R}^{n \\times n_{o}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{\\mathbf{Y}}} \\in \\mathbb{R}^{m \\times n_{o}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\hat{\\mathbf{Y}}}{\\partial \\mathbf{b}} \\in \\mathbb{R}^{(m \\times n_{o}) \\times n_{o}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\hat{\\mathbf{Y}}}{\\partial \\mathbf{W}} \\in \\mathbb{R}^{(m \\times n_{o}) \\times (n \\times n_{o})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca7e21",
   "metadata": {},
   "source": [
    "### MSE derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4405a37",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial \\hat{y}_{pq}} &= \n",
    "\\frac{\\partial}{\\partial \\hat{y}_{pq}} \\left( \\frac{1}{mn_{o}} \\sum_{i=1}^{m} \\sum_{j=1}^{n_o} \\left( \\hat{y}_{ij} - y_{ij} \\right)^{2} \\right) \\\\\n",
    "&= \\frac{1}{mn_{o}} \\sum_{i=1}^{m} \\sum_{j=1}^{n_o} \\frac{\\partial}{\\partial \\hat{y}_{pq}} \\left( \\left( \\hat{y}_{ij} - y_{ij} \\right)^{2} \\right) \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{i=1}^{m} \\sum_{j=1}^{n_o} \\left( \\hat{y}_{ij} - y_{ij} \\right) \\frac{\\partial \\hat{y}_{ij}}{\\partial \\hat{y}_{pq}} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{i=1}^{m} \\sum_{j=1}^{n_o} \\left( \\hat{y}_{ij} - y_{ij} \\right) \\delta_{ip} \\delta_{jq} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{i=1}^{m} \\sum_{j=1}^{n_o} \\left[ \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right]_{ij} \\delta_{ip} \\delta_{jq} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{i=1}^{m} \\sum_{j=1}^{n_o} \\left[ \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right]_{pj} \\delta_{jq} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\left[ \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right]_{pq} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\left( \\hat{y}_{pq} - y_{pq} \\right) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "for $p = 1, \\ldots, m$, and $q = 1, \\ldots, n_{o}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393760e1",
   "metadata": {},
   "source": [
    "Vectorized form\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\hat{\\mathbf{Y}}} = \\frac{2}{mn_{o}} \\left( \n",
    "\\hat{\\mathbf{Y}} - \\mathbf{Y} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988d4aa",
   "metadata": {},
   "source": [
    "### weighted sum derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b91b31",
   "metadata": {},
   "source": [
    "#### respect to bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e72e94",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\hat{y}_{pq}}{\\partial b_{r}} &= \n",
    "\\frac{\\partial}{\\partial b_{r}} \\left( b_{q} + x_{pk} w_{kq} \\right) \\\\\n",
    "&= \\frac{\\partial b_{q}}{\\partial b_{r}} \\\\\n",
    "&= \\delta_{qr}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "for $p = 1, \\ldots, m$, and $q, r = 1, \\ldots, n_{o}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f8317",
   "metadata": {},
   "source": [
    "#### respect to weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21276e6",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\hat{y}_{pq}}{\\partial w_{rs}} &= \n",
    "\\frac{\\partial}{\\partial w_{rs}} \\left( b_{q} + x_{pk} w_{kq} \\right) \\\\\n",
    "&= x_{pk} \\frac{\\partial w_{kq}}{\\partial w_{rs}} \\\\\n",
    "&= x_{pk} \\delta_{kr} \\delta_{qs} \\\\\n",
    "&= x_{pr} \\delta_{qs}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "for $p = 1, \\ldots, m$, for $q, s = 1, \\ldots, n_{o}$, and $r = 1, \\ldots, n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05d570",
   "metadata": {},
   "source": [
    "**Note**: $x_{pk} w_{kq}$ implies summation over the free index $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1cccd7",
   "metadata": {},
   "source": [
    "### full chain rule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed0793",
   "metadata": {},
   "source": [
    "Derivative of MSE respect to bias\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial b_{r}} &= \n",
    "{\\color{Cyan} \\frac{\\partial L}{\\partial \\hat{y}_{pq}}}\n",
    "{\\color{Orange} \\frac{\\partial \\hat{y}_{pq}}{\\partial b_{r}}} \\\\\n",
    "&= \\sum_{p=1}^{m} \\sum_{q=1}^{n_{o}} {\\color{Cyan} \\frac{2}{mn_{o}} \\left( \\hat{y}_{pq} - y_{pq} \\right)} \n",
    "{\\color{Orange} \\delta_{qr}} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{p=1}^{m} \\sum_{q=1}^{n_{o}} \\left[ \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right]_{pq} \\delta_{qr} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{p=1}^{m} \\left[ \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right]_{pr} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{p=1}^{m} \\left( \\hat{y}_{pr} - y_{pr} \\right) \\\\\n",
    "&= \\frac{2}{mn_{o}} \\left< \\mathbf{1}, \\hat{\\mathbf{y}}_{:,r} - \\mathbf{y}_{:,r} \\right> \\\\\n",
    "&= \\frac{2}{mn_{o}} \\mathbf{1}^{\\top} \\left( \\hat{\\mathbf{y}}_{:,r} - \\mathbf{y}_{:,r} \\right) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "for $r = 1, \\ldots, n_{o}$, where $\\mathbf{1} \\in \\mathbb{R}^{m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd0827",
   "metadata": {},
   "source": [
    "**Note**: We made the summations explicit for greater clarity for the inner product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ea695",
   "metadata": {},
   "source": [
    "Vectorized form\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{b}} = \\frac{2}{mn_{o}}\n",
    "\\mathbf{1}^{\\top} \\left( \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e7351",
   "metadata": {},
   "source": [
    "Derivative of MSE respect to weight\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial L}{\\partial w_{rs}} &= \n",
    "{\\color{Cyan} \\frac{\\partial L}{\\partial \\hat{y}_{pq}}}\n",
    "{\\color{Orange} \\frac{\\partial \\hat{y}_{pq}}{\\partial w_{rs}}} \\\\\n",
    "&= \\sum_{p=1}^{m} \\sum_{q=1}^{n_{o}}\n",
    "{\\color{Cyan} \\frac{2}{mn_{o}} \\left( \\hat{y}_{pq} - y_{pq} \\right)} \n",
    "{\\color{Orange} x_{pr} \\delta_{qs}} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{p=1}^{m} \\sum_{q=1}^{n_{o}} \\left[ \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right]_{pq} x_{pr} \\delta_{qs} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{p=1}^{m} \\left[ \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right]_{ps} x_{pr} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\sum_{p=1}^{m} \\left( \\hat{y}_{ps} - y_{ps} \\right) x_{pr} \\\\\n",
    "&= \\frac{2}{mn_{o}} \\left< \\mathbf{x}_{:,r}, \\hat{\\mathbf{y}}_{:,s} - \\mathbf{y}_{:,s} \\right> \\\\\n",
    "&= \\frac{2}{mn_{o}} (\\mathbf{x}_{:,r})^{\\top} \\left( \\hat{\\mathbf{y}}_{:,s} - \\mathbf{y}_{:,s} \\right) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "for $r = 1, \\ldots, n$, and $s = 1, \\ldots, n_{o}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a7a03",
   "metadata": {},
   "source": [
    "**Note**:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{:,r} = \\begin{bmatrix}\n",
    "    x_{1r} & \\cdots & x_{mr}\n",
    "\\end{bmatrix}^{\\top}\n",
    "$$\n",
    "is the $f$-th input features of all input samples. \n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{y}}_{:,r} = \\begin{bmatrix}\n",
    "    \\hat{y}_{1s} & \\cdots & \\hat{y}_{ms}\n",
    "\\end{bmatrix}^{\\top} \\\\\n",
    "\\mathbf{y}_{:,r} = \\begin{bmatrix}\n",
    "    y_{1s} & \\cdots & y_{ms}\n",
    "\\end{bmatrix}^{\\top}\n",
    "$$\n",
    "\n",
    "$\\hat{\\mathbf{y}}_{:,r}, \\mathbf{y}_{:,r}$ is the $s$-th \n",
    "output feature of all predicted and target data samples respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442d47d0",
   "metadata": {},
   "source": [
    "Vectorized form\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\mathbf{W}} = \\frac{2}{mn_{o}}\n",
    "\\mathbf{X}^{\\top} \\left( \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380b69f",
   "metadata": {},
   "source": [
    "### final gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4403a4",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_{\\mathbf{b}}L = \\frac{2}{m n_{o}} \\mathbf{1}^{\\top}\n",
    "\\left( \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618ca367",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_{\\mathbf{W}}L = \\frac{2}{m n_{o}} \\mathbf{X}^{\\top}\n",
    "\\left( \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97d244b",
   "metadata": {},
   "source": [
    "## parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4a0b1",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{b} &\\leftarrow \\mathbf{b} - \\eta \\nabla_{\\mathbf{b}} L \\\\\n",
    "&= \\mathbf{b} - \\eta \\left( \\frac{2}{m n_{o}} \\mathbf{1}^{\\top}\n",
    "\\left( \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right) \\right)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1f9799",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\mathbf{W} &\\leftarrow \\mathbf{W} - \\eta \\nabla_{\\mathbf{W}} L \\\\\n",
    "&= \\mathbf{W} - \\eta \\left( \\frac{2}{m n_{o}} \\mathbf{X}^{\\top}\n",
    "\\left( \\hat{\\mathbf{Y}} - \\mathbf{Y} \\right) \\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $eta \\in \\mathbb{R}^{+}$ is called *learning rate*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e62d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultioutputRegression)\n",
    "def update(self, x: torch.Tensor, y_true: torch.Tensor, \n",
    "           y_pred: torch.Tensor, lr: float):\n",
    "    \"\"\"\n",
    "    Update the model parameters.\n",
    "\n",
    "    Args:\n",
    "       x: Input tensor of shape (n_samples, n_features).\n",
    "       y_true: Target tensor of shape (n_samples, out_features).\n",
    "       y_pred: Predicted output tensor of shape (n_samples, out_features).\n",
    "       lr: Learning rate. \n",
    "    \"\"\"\n",
    "    delta = 2 * (y_pred - y_true) / y_true.numel()\n",
    "    self.b -= lr * delta.sum(axis=0)\n",
    "    self.w -= lr * torch.matmul(x.T, delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84f86de",
   "metadata": {},
   "source": [
    "## gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef212078",
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(MultioutputRegression)\n",
    "def fit(self, x_train: torch.Tensor, y_train: torch.Tensor, \n",
    "        epochs: int, lr: float, batch_size: int, \n",
    "        x_valid: torch.Tensor, y_valid: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Fit the model using gradient descent.\n",
    "    \n",
    "    Args:\n",
    "        x_train: Input tensor of shape (n_samples, n_features).\n",
    "        y_train: Target tensor of shape (n_samples, out_features).\n",
    "        epochs: Number of epochs to fit.\n",
    "        lr: learning rate.\n",
    "        batch_size: Int number of batch.\n",
    "        x_valid: Input tensor of shape (n_valid_samples, n_features).\n",
    "        y_valid: Target tensor of shape (n_valid_samples, out_features)\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        loss = []\n",
    "        for batch in range(0, len(y_train), batch_size):\n",
    "            end_batch = batch + batch_size\n",
    "\n",
    "            y_pred = self.predict(x_train[batch:end_batch])\n",
    "\n",
    "            loss.append(self.mse_loss(\n",
    "                y_train[batch:end_batch], \n",
    "                y_pred\n",
    "            ))\n",
    "\n",
    "            self.update(\n",
    "                x_train[batch:end_batch], \n",
    "                y_train[batch:end_batch], \n",
    "                y_pred, \n",
    "                lr\n",
    "            )\n",
    "\n",
    "        loss = round(sum(loss) / len(loss), 4)\n",
    "        loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "        print(f'epoch: {epoch} - MSE: {loss} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fac0bd",
   "metadata": {},
   "source": [
    "# Scratch vs Torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a53d40",
   "metadata": {},
   "source": [
    "## Torch.nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193dee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchLinearRegression(nn.Module):\n",
    "    def __init__(self, n_features, n_out_features):\n",
    "        super(TorchLinearRegression, self).__init__()\n",
    "        self.layer = nn.Linear(n_features, n_out_features, device=device)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.forward(x)\n",
    "            return self.loss(y_pred, y).item()\n",
    "    \n",
    "    def fit(self, x, y, epochs, lr, batch_size, x_valid, y_valid):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n",
    "        for epoch in range(epochs):\n",
    "            loss_t = []\n",
    "            for batch in range(0, len(y), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "\n",
    "                y_pred = self.forward(x[batch:end_batch])\n",
    "                loss = self.loss(y_pred, y[batch:end_batch])\n",
    "                loss_t.append(loss.item())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            loss_t = round(sum(loss_t) / len(loss_t), 4)\n",
    "            loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "            print(f'epoch: {epoch} - MSE: {loss_t} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee5b6b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchLinearRegression(N, NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51699fa1",
   "metadata": {},
   "source": [
    "## scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53096ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultioutputRegression(N, NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41673bf",
   "metadata": {},
   "source": [
    "## evals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2928e916",
   "metadata": {},
   "source": [
    "We will use a metric to compare our model with the PyTorch model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16917477",
   "metadata": {},
   "source": [
    "### import MAPE modified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47c813",
   "metadata": {},
   "source": [
    "We will use a modification of *MAPE* as a metric\n",
    "\n",
    "$$\n",
    "\\text{MAPE}(\\mathbf{Y}, \\hat{\\mathbf{Y}}) = \\frac{1}{mn_{o}}\n",
    "\\sum^{m}_{i=1} \\sum^{n_{o}}_{j=1} \\mathcal{L} (y_{ij}, \\hat{y}_{ij})\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathcal{L} (y_{ij}, \\hat{y}_{ij}) = \\begin{cases}\n",
    "    \\left| \\frac{y_{ij} - \\hat{y}_{ij}}{y_{ij}} \\right|\n",
    "    & \\text{if } y_{ij} \\neq 0 \\\\\n",
    "    \\left| \\hat{y}_{ij} \\right| & \\text{if } \\hat{y}_{ij} = 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d29c50fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mape imported locally.\n"
     ]
    }
   ],
   "source": [
    "# This cell imports torch_mape \n",
    "# if you are running this notebook locally \n",
    "# or from Google Colab.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "try:\n",
    "    from tools.torch_metrics import torch_mape as mape\n",
    "    print('mape imported locally.')\n",
    "except ModuleNotFoundError:\n",
    "    import subprocess\n",
    "\n",
    "    repo_url = 'https://raw.githubusercontent.com/PilotLeoYan/inside-deep-learning/main/content/tools/torch_metrics.py'\n",
    "    local_file = 'torch_metrics.py'\n",
    "    \n",
    "    subprocess.run(['wget', repo_url, '-O', local_file], check=True)\n",
    "    try:\n",
    "        from torch_metrics import torch_mape as mape # type: ignore\n",
    "        print('mape imported from GitHub.')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f163307d",
   "metadata": {},
   "source": [
    "### predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a3b50",
   "metadata": {},
   "source": [
    "Let’s compare the predictions of our model and PyTorch’s using modified MAPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a49552c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.923027994040694"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae3024",
   "metadata": {},
   "source": [
    "They differ considerably because each model has its own parameters initialized randomly and independently of the other model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1953d8b7",
   "metadata": {},
   "source": [
    "### copy parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4564ad6f",
   "metadata": {},
   "source": [
    "We copy the values of the PyTorch model parameters to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c649aa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.copy_params(torch_model.layer)\n",
    "parameters = (model.b.clone(), model.w.clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01bd130",
   "metadata": {},
   "source": [
    "### predictions after copy parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33998cfa",
   "metadata": {},
   "source": [
    "We measure the difference between the predictions of both models again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f222f0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a5b29",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d6c7662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.evaluate(X_valid, Y_valid),\n",
    "    torch_model.evaluate(X_valid, Y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a2a74",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634601f4",
   "metadata": {},
   "source": [
    "We are going to train both models using the same hyperparameters’ value. If our model is well designed, then starting from the same parameters it should arrive at the same parameters’ values as the PyTorch model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a1b892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR: float = 0.01 # learning rate\n",
    "EPOCHS: int = 16 # number of epochs\n",
    "BATCH: int = len(X_train) // 3 # batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bfd64b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 12337.0229 - MSE_v: 14219.263\n",
      "epoch: 1 - MSE: 11741.1533 - MSE_v: 13604.0188\n",
      "epoch: 2 - MSE: 11177.6772 - MSE_v: 13018.4171\n",
      "epoch: 3 - MSE: 10644.6031 - MSE_v: 12460.8525\n",
      "epoch: 4 - MSE: 10140.077 - MSE_v: 11929.8174\n",
      "epoch: 5 - MSE: 9662.3718 - MSE_v: 11423.8961\n",
      "epoch: 6 - MSE: 9209.878 - MSE_v: 10941.7576\n",
      "epoch: 7 - MSE: 8781.0948 - MSE_v: 10482.1507\n",
      "epoch: 8 - MSE: 8374.6218 - MSE_v: 10043.8982\n",
      "epoch: 9 - MSE: 7989.1517 - MSE_v: 9625.8922\n",
      "epoch: 10 - MSE: 7623.4634 - MSE_v: 9227.0893\n",
      "epoch: 11 - MSE: 7276.4158 - MSE_v: 8846.5065\n",
      "epoch: 12 - MSE: 6946.9418 - MSE_v: 8483.2175\n",
      "epoch: 13 - MSE: 6634.043 - MSE_v: 8136.3485\n",
      "epoch: 14 - MSE: 6336.7849 - MSE_v: 7805.0753\n",
      "epoch: 15 - MSE: 6054.2921 - MSE_v: 7488.62\n"
     ]
    }
   ],
   "source": [
    "torch_model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH, \n",
    "    X_valid, Y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c39adfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 12337.0229 - MSE_v: 14219.263\n",
      "epoch: 1 - MSE: 11741.1533 - MSE_v: 13604.0188\n",
      "epoch: 2 - MSE: 11177.6772 - MSE_v: 13018.4171\n",
      "epoch: 3 - MSE: 10644.6031 - MSE_v: 12460.8525\n",
      "epoch: 4 - MSE: 10140.077 - MSE_v: 11929.8174\n",
      "epoch: 5 - MSE: 9662.3718 - MSE_v: 11423.8961\n",
      "epoch: 6 - MSE: 9209.878 - MSE_v: 10941.7576\n",
      "epoch: 7 - MSE: 8781.0948 - MSE_v: 10482.1507\n",
      "epoch: 8 - MSE: 8374.6218 - MSE_v: 10043.8982\n",
      "epoch: 9 - MSE: 7989.1517 - MSE_v: 9625.8922\n",
      "epoch: 10 - MSE: 7623.4634 - MSE_v: 9227.0893\n",
      "epoch: 11 - MSE: 7276.4158 - MSE_v: 8846.5065\n",
      "epoch: 12 - MSE: 6946.9418 - MSE_v: 8483.2175\n",
      "epoch: 13 - MSE: 6634.043 - MSE_v: 8136.3485\n",
      "epoch: 14 - MSE: 6336.7849 - MSE_v: 7805.0753\n",
      "epoch: 15 - MSE: 6054.2921 - MSE_v: 7488.62\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH, \n",
    "    X_valid, Y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730bbbf",
   "metadata": {},
   "source": [
    "### predictions after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0411af96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6160601912622177e-16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4377a0",
   "metadata": {},
   "source": [
    "### bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f36a5",
   "metadata": {},
   "source": [
    "We directly measure the difference between the bias values of both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a018cffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5425981536262703e-16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.b.clone(),\n",
    "    torch_model.layer.bias.detach()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801a61b",
   "metadata": {},
   "source": [
    "### weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e04c2c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1928055724331222e-16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.w.clone(),\n",
    "    torch_model.layer.weight.detach().T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34cffd",
   "metadata": {},
   "source": [
    "All right, our implementation is correct respect to PyTorch. \n",
    "We have finished this section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c8e54",
   "metadata": {},
   "source": [
    "# Compute gradients with einsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776d738",
   "metadata": {},
   "source": [
    "This implementation is similar, but only changed parameters update\n",
    "with einsum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c64f9",
   "metadata": {},
   "source": [
    "If we change the weighted sum to avoid broadcasting\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{Y}} (\\mathbf{X}) = \\mathbf{1 \\otimes b + XW}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{1} \\in \\mathbb{R}^{m}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd055bb",
   "metadata": {},
   "source": [
    "**Remark**: $\\otimes$ is outer product.\n",
    "\n",
    "$$\n",
    "\\mathbf{1 \\otimes b} = \\begin{bmatrix}\n",
    "\tb_{1} & \\cdots & b_{n_{o}} \\\\\n",
    "\t\\vdots & \\ddots & \\vdots \\\\\n",
    "\tb_{1} & \\cdots & b_{n_{o}}\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{m \\times n_{o}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1c18de",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\hat{y}_{pq}}{\\partial b_{r}} &= \n",
    "\\frac{\\partial}{\\partial b_{r}} \\left( 1_{p} b_{q} + x_{pk} w_{kq} \\right) \\\\\n",
    "&= 1_{p} \\frac{\\partial b_{q}}{\\partial b_{r}} \\\\\n",
    "&= 1_{p} \\delta_{qr} \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84187aae",
   "metadata": {},
   "source": [
    "The derivative of weighted sum respect to bias is compute as\n",
    "\n",
    "```python\n",
    "b_der = torch.einsum(\n",
    "    'p,qr->pqr', \n",
    "    torch.ones(m), # the tensor of 1\n",
    "    torch.eye(no) # kronecker delta\n",
    ") # result is a tensor of order 3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06064cc",
   "metadata": {},
   "source": [
    "The derivative of weighted sum respect to weight no changes\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\hat{y}_{pq}}{\\partial w_{rs}} = \n",
    "x_{pr} \\delta_{qs}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9de47b",
   "metadata": {},
   "source": [
    "and it is compute as\n",
    "\n",
    "```python\n",
    "w_der = torch.einsum(\n",
    "    'pr,qs->pqrs', \n",
    "    x, \n",
    "    torch.eye(no)\n",
    ") # result is a tensor of order 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8463ab0",
   "metadata": {},
   "source": [
    "To compute the chain rule\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial b_{r}} = \n",
    "{\\color{Cyan} \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}_{pq}}}\n",
    "{\\color{Orange} \\frac{\\partial \\hat{y}_{pq}}{\\partial b_{r}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02abc51",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.einsum('pq,pqr->r', delta, b_der)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34616195",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial \\text{MSE}}{\\partial w_{rs}} = \n",
    "{\\color{Cyan} \\frac{\\partial \\text{MSE}}{\\partial \\hat{y}_{pq}}}\n",
    "{\\color{Orange} \\frac{\\partial \\hat{y}_{pq}}{\\partial w_{rs}}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782fbd8b",
   "metadata": {},
   "source": [
    "```python\n",
    "torch.einsum('pq,pqrs->rs', delta, w_der)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8153d2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EinsumLinearRegression(MultioutputRegression):\n",
    "    def update(self, x: torch.Tensor, y_true: torch.Tensor, \n",
    "               y_pred: torch.Tensor, lr: float):\n",
    "        \"\"\"\n",
    "        Update the model parameters.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (n_samples, n_features).\n",
    "            y_true: Target tensor of shape (n_samples, n_features).\n",
    "            y_pred: Predicted output tensor of shape (n_samples, n_features).\n",
    "            lr: Learning rate. \n",
    "        \"\"\"\n",
    "        m, no = y_true.shape\n",
    "\n",
    "        # d L / d Y_pred\n",
    "        delta = 2 * (y_pred - y_true) / y_true.numel()\n",
    "\n",
    "        # d L / d b\n",
    "        b_der = torch.einsum(\n",
    "            'p,qr->pqr', \n",
    "            torch.ones(m, device=device), # the tensor of 1\n",
    "            torch.eye(no, device=device))\n",
    "        self.b -= lr * torch.einsum('pq,pqr->r', delta, b_der)\n",
    "\n",
    "        # d L / d W\n",
    "        w_der = torch.einsum('pr,qs->pqrs', x, torch.eye(no, device=device))\n",
    "        self.w -= lr * torch.einsum('pq,pqrs->rs', delta, w_der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f735711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0743,  0.0080,  0.3463],\n",
       "        [ 0.1673, -0.1174,  0.3864],\n",
       "        [-0.1898,  0.3644,  0.3414],\n",
       "        [ 0.1468,  0.0298, -0.0997],\n",
       "        [-0.3986, -0.2187,  0.0296],\n",
       "        [ 0.2073, -0.3257, -0.0527]], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einsum_model = EinsumLinearRegression(N, NO)\n",
    "einsum_model.b.copy_(parameters[0])\n",
    "einsum_model.w.copy_(parameters[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f895c169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 12337.0229 - MSE_v: 14219.263\n",
      "epoch: 1 - MSE: 11741.1533 - MSE_v: 13604.0188\n",
      "epoch: 2 - MSE: 11177.6772 - MSE_v: 13018.4171\n",
      "epoch: 3 - MSE: 10644.6031 - MSE_v: 12460.8525\n",
      "epoch: 4 - MSE: 10140.077 - MSE_v: 11929.8174\n",
      "epoch: 5 - MSE: 9662.3718 - MSE_v: 11423.8961\n",
      "epoch: 6 - MSE: 9209.878 - MSE_v: 10941.7576\n",
      "epoch: 7 - MSE: 8781.0948 - MSE_v: 10482.1507\n",
      "epoch: 8 - MSE: 8374.6218 - MSE_v: 10043.8982\n",
      "epoch: 9 - MSE: 7989.1517 - MSE_v: 9625.8922\n",
      "epoch: 10 - MSE: 7623.4634 - MSE_v: 9227.0893\n",
      "epoch: 11 - MSE: 7276.4158 - MSE_v: 8846.5065\n",
      "epoch: 12 - MSE: 6946.9418 - MSE_v: 8483.2175\n",
      "epoch: 13 - MSE: 6634.043 - MSE_v: 8136.3485\n",
      "epoch: 14 - MSE: 6336.7849 - MSE_v: 7805.0753\n",
      "epoch: 15 - MSE: 6054.2921 - MSE_v: 7488.62\n"
     ]
    }
   ],
   "source": [
    "einsum_model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH, \n",
    "    X_valid, Y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f08e8b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.218213318774402e-17"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    einsum_model.w.clone(),\n",
    "    torch_model.layer.weight.detach().T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b05c2ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8222064269950653e-16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    einsum_model.b.clone(),\n",
    "    torch_model.layer.bias.detach()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
