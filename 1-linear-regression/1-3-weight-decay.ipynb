{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 - Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/PilotLeoYan/inside-deep-learning/blob/main/1-linear-regression/1-3-weight-decay.ipynb\">\n",
    "    <img src=\"../images/colab_logo.png\" width=\"32\">Open in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.org/github/PilotLeoYan/inside-deep-learning/blob/main/1-linear-regression/1-3-weight-decay.ipynb\">\n",
    "    <img src=\"../images/jupyter_logo.png\" width=\"32\">Open in Jupyter NBViewer</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue from our multivariate linear regression. \n",
    "Now let's incorporate the $\\ell_2$ regularization ($L_{2}$) into our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose of this Notebook**:\n",
    "\n",
    "The purposes of this notebook are:\n",
    "1. Incorporate $\\ell_2$ regularization into our Perceptron from scratch\n",
    "2. Train our Perceptron\n",
    "5. Compare our Perceptron to the one prebuilt by PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.13.5', '2.7.1+cu128')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from platform import python_version\n",
    "python_version(), torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):  \n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj): setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{X} &\\in \\mathbb{R}^{m \\times n} \\\\\n",
    "\\mathbf{Y} &\\in \\mathbb{R}^{m \\times n_{1}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 6)\n",
      "(10100, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import random\n",
    "\n",
    "M: int = 10_100 # number of samples\n",
    "N: int = 6 # number of input features\n",
    "NO: int = 3 # number of output features\n",
    "\n",
    "X, Y = make_regression(\n",
    "    n_samples=M, \n",
    "    n_features=N, \n",
    "    n_targets=NO, \n",
    "    n_informative=N - 1,\n",
    "    bias=random.random(),\n",
    "    noise=1\n",
    ")\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 6]), torch.Size([100, 3]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X[:100], device=device)\n",
    "Y_train = torch.tensor(Y[:100], device=device)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000, 6]), torch.Size([10000, 3]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid = torch.tensor(X[100:], device=device)\n",
    "Y_valid = torch.tensor(Y[100:], device=device)\n",
    "X_valid.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing we are going to modify is the way in which the model weights are updated. \n",
    "The rest, such as parameter initialization and model training, remain unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, n_features: int, out_features: int, lambd: float):\n",
    "        self.w = torch.randn(n_features, out_features, device=device)\n",
    "        self.b = torch.randn(out_features, device=device)\n",
    "        self.lambd = lambd\n",
    "\n",
    "    def copy_params(self, torch_layer: torch.nn.modules.linear.Linear):\n",
    "        \"\"\"\n",
    "        Copy the parameters from a module.linear to this model.\n",
    "\n",
    "        Args:\n",
    "            torch_layer: Pytorch module from which to copy the parameters.\n",
    "        \"\"\"\n",
    "        self.b.copy_(torch_layer.bias.detach().clone())\n",
    "        self.w.copy_(torch_layer.weight.T.detach().clone())\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict the output for input x\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (n_samples, n_features).\n",
    "\n",
    "        Returns:\n",
    "            y_pred: Predicted output tensor of shape (n_samples, out_features).\n",
    "        \"\"\"\n",
    "        return torch.matmul(x, self.w) + self.b\n",
    "\n",
    "    def mse_loss(self, y_true: torch.Tensor, y_pred: torch.Tensor):\n",
    "        \"\"\"\n",
    "        MSE loss function between target y_true and y_pred.\n",
    "\n",
    "        Args:\n",
    "            y_true: Target tensor of shape (n_samples, out_features).\n",
    "            y_pred: Predicted tensor of shape (n_samples, out_features).\n",
    "\n",
    "        Returns:\n",
    "            loss: MSE loss between predictions and true values.\n",
    "        \"\"\"\n",
    "        return ((y_pred - y_true)**2).mean().item()\n",
    "\n",
    "    def evaluate(self, x: torch.Tensor, y_true: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Evaluate the model on input x and target y_true using MSE.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (n_samples, n_features).\n",
    "            y_true: Target tensor of shape (n_samples, out_features).\n",
    "\n",
    "        Returns:\n",
    "            loss: MSE loss between predictions and true values.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        return self.mse_loss(y_true, y_pred)\n",
    "\n",
    "    def fit(self, x_train: torch.Tensor, y_train: torch.Tensor, \n",
    "        epochs: int, lr: float, batch_size: int, \n",
    "        x_valid: torch.Tensor, y_valid: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Fit the model using gradient descent.\n",
    "        \n",
    "        Args:\n",
    "            x_train: Input tensor of shape (n_samples, n_features).\n",
    "            y_train: Target tensor of shape (n_samples,).\n",
    "            epochs: Number of epochs to fit.\n",
    "            lr: learning rate.\n",
    "            batch_size: Int number of batch.\n",
    "            x_valid: Input tensor of shape (n_valid_samples, n_features).\n",
    "            y_valid: Target tensor of shape (n_valid_samples,)\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            loss = []\n",
    "            for batch in range(0, len(y_train), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "\n",
    "                y_pred = self.predict(x_train[batch:end_batch])\n",
    "\n",
    "                loss.append(self.mse_loss(\n",
    "                    y_train[batch:end_batch], \n",
    "                    y_pred\n",
    "                ))\n",
    "\n",
    "                self.update(\n",
    "                    x_train[batch:end_batch], \n",
    "                    y_train[batch:end_batch], \n",
    "                    y_pred, \n",
    "                    lr\n",
    "                )\n",
    "\n",
    "            loss = round(sum(loss) / len(loss), 4)\n",
    "            loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "            print(f'epoch: {epoch} - MSE: {loss} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of training the model with the gradient of the loss function, \n",
    "we are going to use the objective function $J$. \n",
    "Typically our objective function is as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\hat{\\mathbf{Y}}, \\mathbf{\\theta}) = \n",
    "L(\\hat{\\mathbf{Y}}) + \\text{regularization}\n",
    "$$\n",
    "where $\\mathbf{\\theta}$ is an arbitrary parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Do not use the objective function to evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a weight decay technique, we will use regularization, commonly $\\ell_2$ or $L_{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ell_2(\\mathbf{\\theta}) = \n",
    "\\frac{\\lambda}{2} \\left\\| \\mathbf{\\theta} \\right\\|^{2}_{2}\n",
    "$$\n",
    "where commonly $\\mathbf{\\theta} \\in \\mathbb{R}^{n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: $\\lambda \\in \\mathbb{R}$ is called as a *hyperparameter*, \n",
    "because it is a parameter set by the developer (you) not by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we have $\\mathbf{W} \\in \\mathbb{R}^{n \\times n_{1}}$, then we need to do an equivalence operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\ell_2(\\mathbf{W}) &= \\frac{\\lambda}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n_{1}} w_{ij}^{2} \\\\\n",
    "&= \\frac{\\lambda}{2} \\text{sum} \\left( \\mathbf{W}^{2} \\right) \n",
    "\\end{align*}\n",
    "$$\n",
    "where ${\\mathbf{A}}^2$ is element-wise power or also ${\\mathbf{A}}^2 = \\mathbf{A} \\odot \\mathbf{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### objective function derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J}{\\partial w_{pq}} =\n",
    "\\frac{\\partial L}{\\partial w_{pq}} +\n",
    "\\frac{\\partial \\ell_2}{\\partial w_{pq}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\ell_2}{\\partial w_{pq}} &=\n",
    "\\frac{\\lambda}{2} \\sum_{i=1}^{n} \\sum_{j=1}^{n_{1}}\n",
    "\\frac{\\partial}{\\partial w_{pq}} \\left( \n",
    "    w_{ij}^{2}\n",
    "\\right) \\\\\n",
    "&= \\lambda w_{pq}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because\n",
    "$$\n",
    "\\frac{\\partial w_{ij}}{\\partial w_{pq}} = \\begin{cases}\n",
    "    1 & \\text{if } i=p, j=q \\\\\n",
    "    0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, for all $p = 1, \\ldots, n$ and $q = 1, \\ldots, n_{1}$.\n",
    "$$\n",
    "\\frac{\\partial \\ell_2}{\\partial \\mathbf{W}} =\n",
    "\\lambda \\mathbf{W}\n",
    "$$\n",
    "**Remark**: $\\nabla_{\\mathbf{W}}\\ell_2 \\in \\mathbb{R}^{n \\times n_{1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial J}{\\partial \\mathbf{W}} &=\n",
    "{\\color{Orange} {\\frac{\\partial L}{\\partial \\mathbf{W}}}} +\n",
    "{\\color{Cyan} {\\frac{\\partial \\ell_2}{\\partial \\mathbf{W}}}} \\\\\n",
    "&= {\\color{Orange} {\\nabla_{\\mathbf{W}}L}} + \n",
    "{\\color{Cyan} {\\lambda \\mathbf{W}}}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_to_class(LinearRegression)\n",
    "def update(self, x: torch.Tensor, y_true: torch.Tensor, y_pred: torch.Tensor, lr: float):\n",
    "    \"\"\"\n",
    "    Update the model parameters with L2 regularization.\n",
    "\n",
    "    Args:\n",
    "       x: Input tensor of shape (n_samples, n_features).\n",
    "       y_true: Target tensor of shape (n_samples, n_features).\n",
    "       y_pred: Predicted output tensor of shape (n_samples, n_features).\n",
    "       lr: Learning rate. \n",
    "    \"\"\"\n",
    "    delta = 2 * (y_pred - y_true) / y_true.numel()\n",
    "    self.b -= lr * delta.sum(axis=0)\n",
    "    self.w -= lr * (torch.matmul(x.T, delta) + self.lambd * self.w) # L2 regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch vs Torch.nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch.nn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchLinearRegression(nn.Module):\n",
    "    def __init__(self, n_features, n_out_features):\n",
    "        super(TorchLinearRegression, self).__init__()\n",
    "        self.layer = nn.Linear(n_features, n_out_features, device=device)\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer(x)\n",
    "    \n",
    "    def evaluate(self, x, y):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.forward(x)\n",
    "            return self.loss(y_pred, y).item()\n",
    "    \n",
    "    def fit(self, x, y, epochs, lr, batch_size, x_valid, y_valid, weight_decay):\n",
    "        \n",
    "        optimizer = torch.optim.SGD([\n",
    "            {'params': self.layer.weight, 'weight_decay': weight_decay},\n",
    "            {'params': self.layer.bias} # it is important to specify the weight decay for the bias.\n",
    "        ], lr=lr)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss_t = []\n",
    "            for batch in range(0, len(y), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "\n",
    "                y_pred = self.forward(x[batch:end_batch])\n",
    "                loss = self.loss(y_pred, y[batch:end_batch])\n",
    "                loss_t.append(loss.item())\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            loss_t = round(sum(loss_t) / len(loss_t), 4)\n",
    "            loss_v = round(self.evaluate(x_valid, y_valid), 4)\n",
    "            print(f'epoch: {epoch} - MSE: {loss_t} - MSE_v: {loss_v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchLinearRegression(N, NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAMBD: float = 0.01\n",
    "\n",
    "model = LinearRegression(N, NO, LAMBD)\n",
    "model.lambd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import MAPE modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import importlib.util\n",
    "from collections.abc import Callable\n",
    "\n",
    "def import_mape(module_path: str = '..') -> Callable:\n",
    "    \"\"\"\n",
    "    Tries to import the 'torch_mape' function from a local project structure.\n",
    "    If it fails (ModuleNotFoundError), it assumes a cloud environment (like Colab),\n",
    "    downloads the module from GitHub, imports it, and returns the function.\n",
    "\n",
    "    Args:\n",
    "        module_path (str): The relative path to the project's root directory\n",
    "                           for the local search.\n",
    "\n",
    "    Returns:\n",
    "        The imported 'torch_mape' function, or None if it fails.\n",
    "    \"\"\"\n",
    "    GITHUB_RAW_URL = 'https://raw.githubusercontent.com/PilotLeoYan/inside-deep-learning/main/tools/torch_metrics.py'\n",
    "    MODULE_NAME = 'torch_metrics'\n",
    "    LOCAL_FILE_NAME = f'{MODULE_NAME}.py'\n",
    "\n",
    "    try:\n",
    "        # Attempt 1: Standard import (if the package is installed or in PYTHONPATH)\n",
    "        from tools.torch_metrics import torch_mape\n",
    "        print(\"✅ Module 'tools.torch_metrics' successfully imported from the environment.\")\n",
    "        return torch_mape\n",
    "\n",
    "    except ModuleNotFoundError:\n",
    "        # Attempt 2: Search in the specified local path (original behavior)\n",
    "        # This is useful for local development without installing the package.\n",
    "        project_path = os.path.abspath(os.path.join(module_path))\n",
    "        if project_path not in sys.path:\n",
    "            sys.path.insert(0, project_path)\n",
    "\n",
    "        try:\n",
    "            from tools.torch_metrics import torch_mape\n",
    "            print(\"✅ Local module 'tools.torch_metrics' imported after adjusting the path.\")\n",
    "            # Remove the added path to avoid side effects\n",
    "            sys.path.pop(0)\n",
    "            return torch_mape\n",
    "        except ModuleNotFoundError:\n",
    "            # If both local attempts fail, proceed with the download\n",
    "            if project_path in sys.path:\n",
    "                sys.path.pop(0) # Clean up the path if it was added\n",
    "            print(f\"⚠️ Local module not found. Proceeding to download from GitHub...\")\n",
    "\n",
    "    # Download and Dynamic Loading Logic}\n",
    "    if not os.path.exists(LOCAL_FILE_NAME):\n",
    "        try:\n",
    "            print(f\"⬇️  Downloading '{LOCAL_FILE_NAME}' from GitHub...\")\n",
    "            response = requests.get(GITHUB_RAW_URL)\n",
    "            response.raise_for_status()  # This will raise an error if the HTTP request failed\n",
    "            with open(LOCAL_FILE_NAME, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response.text)\n",
    "            print(\"👍 Download complete.\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"❌ Error downloading the file: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Dynamically load the module using importlib\n",
    "    spec = importlib.util.spec_from_file_location(MODULE_NAME, LOCAL_FILE_NAME)\n",
    "    dynamic_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(dynamic_module)\n",
    "    \n",
    "    print(f\"✅ Module '{MODULE_NAME}' successfully loaded from the downloaded file.\")\n",
    "    return dynamic_module.torch_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Local module 'tools.torch_metrics' imported after adjusting the path.\n"
     ]
    }
   ],
   "source": [
    "mape = import_mape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3941.280306302811"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.copy_params(torch_model.layer)\n",
    "parameters = (model.b.clone(), model.w.clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict after copy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.evaluate(X_valid, Y_valid),\n",
    "    torch_model.evaluate(X_valid, Y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.01 # learning rate\n",
    "EPOCHS = 16 # number of epochs\n",
    "BATCH = len(X_train) // 3 # batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 11924.5458 - MSE_v: 8943.0544\n",
      "epoch: 1 - MSE: 10508.8767 - MSE_v: 8383.9955\n",
      "epoch: 2 - MSE: 9339.9285 - MSE_v: 7887.3242\n",
      "epoch: 3 - MSE: 8368.6366 - MSE_v: 7442.5281\n",
      "epoch: 4 - MSE: 7556.0473 - MSE_v: 7041.1584\n",
      "epoch: 5 - MSE: 6871.2145 - MSE_v: 6676.4069\n",
      "epoch: 6 - MSE: 6289.535 - MSE_v: 6342.7709\n",
      "epoch: 7 - MSE: 5791.431 - MSE_v: 6035.7873\n",
      "epoch: 8 - MSE: 5361.3075 - MSE_v: 5751.8221\n",
      "epoch: 9 - MSE: 4986.7263 - MSE_v: 5487.9032\n",
      "epoch: 10 - MSE: 4657.7531 - MSE_v: 5241.5874\n",
      "epoch: 11 - MSE: 4366.4399 - MSE_v: 5010.8556\n",
      "epoch: 12 - MSE: 4106.4148 - MSE_v: 4794.0288\n",
      "epoch: 13 - MSE: 3872.5586 - MSE_v: 4589.7018\n",
      "epoch: 14 - MSE: 3660.7467 - MSE_v: 4396.6898\n",
      "epoch: 15 - MSE: 3467.6462 - MSE_v: 4213.987\n"
     ]
    }
   ],
   "source": [
    "torch_model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH, \n",
    "    X_valid, Y_valid,\n",
    "    LAMBD\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 - MSE: 11924.5458 - MSE_v: 8943.0544\n",
      "epoch: 1 - MSE: 10508.8767 - MSE_v: 8383.9955\n",
      "epoch: 2 - MSE: 9339.9285 - MSE_v: 7887.3242\n",
      "epoch: 3 - MSE: 8368.6366 - MSE_v: 7442.5281\n",
      "epoch: 4 - MSE: 7556.0473 - MSE_v: 7041.1584\n",
      "epoch: 5 - MSE: 6871.2145 - MSE_v: 6676.4069\n",
      "epoch: 6 - MSE: 6289.535 - MSE_v: 6342.7709\n",
      "epoch: 7 - MSE: 5791.431 - MSE_v: 6035.7873\n",
      "epoch: 8 - MSE: 5361.3075 - MSE_v: 5751.8221\n",
      "epoch: 9 - MSE: 4986.7263 - MSE_v: 5487.9032\n",
      "epoch: 10 - MSE: 4657.7531 - MSE_v: 5241.5874\n",
      "epoch: 11 - MSE: 4366.4399 - MSE_v: 5010.8556\n",
      "epoch: 12 - MSE: 4106.4148 - MSE_v: 4794.0288\n",
      "epoch: 13 - MSE: 3872.5586 - MSE_v: 4589.7018\n",
      "epoch: 14 - MSE: 3660.7467 - MSE_v: 4396.6898\n",
      "epoch: 15 - MSE: 3467.6462 - MSE_v: 4213.987\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH, \n",
    "    X_valid, Y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.961535470546574e-14"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model.forward(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weight "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5086733575246558e-14"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.w.clone(),\n",
    "    torch_model.layer.weight.detach().T\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.972528614591374e-15"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.b.clone(),\n",
    "    torch_model.layer.bias.detach()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-vs-idl-3-13-5 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
