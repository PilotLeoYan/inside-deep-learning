{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a copy of [mlp-like-pytorch](mlp-like-pytorch.ipynb), but in this notebook **cross-entropy loss** is used as the loss function and we show a problem of torch.nn.CrossEntropyLoss which internally uses a softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.12.6', '2.5.1+cu124')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from platform import python_version\n",
    "python_version(), torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):  \n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{X} \\in \\mathbb{R}^{m \\times n} \\\\\n",
    "\\mathbf{Y} \\in \\mathbb{R}^{m \\times n_{\\text{o}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1100, 5)\n",
      "(1100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "M: int = 1_100 # number of samples\n",
    "N: int = 5 # number of input features\n",
    "CLASSES: int = 3 # number of output classes\n",
    "\n",
    "X, Y = make_classification(\n",
    "    n_samples=M, \n",
    "    n_features=N, \n",
    "    n_classes=CLASSES, \n",
    "    n_informative=N - 1, \n",
    "    n_redundant=0\n",
    ")\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1100, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat = nn.functional.one_hot(\n",
    "    torch.tensor(Y, device=device).long(), \n",
    "    CLASSES\n",
    ").type(torch.float32)\n",
    "Y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset into train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 5]), torch.Size([1000, 5]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X[:100], device=device)\n",
    "X_valid = torch.tensor(X[100:], device=device)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3]), torch.Size([1000, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train, Y_valid = Y_hat[:100], Y_hat[100:]\n",
    "Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del Y\n",
    "del Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    is_trainable: bool = False\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense or full conect layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, units: int):\n",
    "        self.units = units\n",
    "        self.is_trainable = True\n",
    "\n",
    "    def set_params(self, w: torch.Tensor, b: torch.Tensor) -> None:\n",
    "        self.w.copy_(w.T.detach().clone())\n",
    "        self.b.copy_(b.detach().clone())\n",
    "\n",
    "    def construct(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Initialize the parameters\n",
    "        self.w := tensor (n_features, units).\n",
    "        self.b := tensor (units).\n",
    "        \n",
    "        Args:\n",
    "            x: input tensor of shape (m_samples, n_features).\n",
    "        \n",
    "        Return:\n",
    "            z: out tensor of shape (m_samples, units).\n",
    "        \"\"\"\n",
    "        n_features = x.shape[-1]\n",
    "        self.w = torch.randn(n_features, self.units, device=device)\n",
    "        self.b = torch.randn(self.units, device=device)\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute weighted sum Z = XW+b.\n",
    "        \n",
    "        Args:\n",
    "            x: input tensor of shape (m_samples, n_features).\n",
    "            \n",
    "        Return:\n",
    "            z: out tensor of shape (m_samples, units).\n",
    "        \"\"\"\n",
    "        return torch.matmul(x, self.w) + self.b\n",
    "\n",
    "    def __forward__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward propagation for training step.\"\"\"\n",
    "        self.input = x.clone()\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def backward(self, delta, lr: float) -> torch.Tensor:\n",
    "        # bias der and update\n",
    "        self.b -= lr * torch.sum(delta, axis=0)\n",
    "        # weight derivative (update weight after compute input der)\n",
    "        w_der = torch.matmul(self.input.T, delta)\n",
    "        # input derivative\n",
    "        delta = torch.matmul(delta, self.w.T)\n",
    "        # weight update\n",
    "        self.w -= lr * w_der\n",
    "        return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Layer):\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        #return torch.relu(z)\n",
    "        return torch.max(z, torch.zeros_like(z))\n",
    "    \n",
    "    def __forward__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        self.a = self.forward(z)\n",
    "        return self.a\n",
    "    \n",
    "    def construct(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(z)\n",
    "    \n",
    "    def backward(self, delta, lr: float):\n",
    "        return delta * (1 * (self.a > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        #return torch.sigmoid(z)\n",
    "        return 1 / (1 + torch.exp(-z))\n",
    "    \n",
    "    def __forward__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        self.a = self.forward(z)\n",
    "        return self.a\n",
    "    \n",
    "    def construct(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(z)\n",
    "    \n",
    "    def backward(self, delta, lr: float):\n",
    "        return delta * (self.a * (1 - self.a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Layer):\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        #return torch.tanh(z)\n",
    "        exp = torch.exp(-2 * z)\n",
    "        return (1 - exp) / (1 + exp)\n",
    "    \n",
    "    def __forward__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        self.a = self.forward(z)\n",
    "        return self.a\n",
    "    \n",
    "    def construct(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(z)\n",
    "\n",
    "    def backward(self, delta, lr: float):\n",
    "        return delta * (1 - self.a**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        exp = torch.exp(z - torch.max(z, dim=1, keepdims=True)[0])\n",
    "        return exp / exp.sum(1, keepdims=True)\n",
    "    \n",
    "    def __forward__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        self.a = self.forward(z)\n",
    "        return self.a\n",
    "    \n",
    "    def construct(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(z)\n",
    "    \n",
    "    def backward(self, delta, lr: float):\n",
    "        return self.a * (delta - (delta * self.a).sum(axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputLayer(Layer):\n",
    "    def __init__(self, n_input_features: int):\n",
    "        self.m = 10\n",
    "        self.n = n_input_features\n",
    "\n",
    "    def construct(self) -> torch.Tensor:\n",
    "        return torch.randn(self.m, self.n, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Losses:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Losses):\n",
    "    def loss(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "        return ((y_pred - y_true)**2).mean().item()\n",
    "\n",
    "    def __call__(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "        return self.loss(y_pred, y_true)\n",
    "\n",
    "    def backward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return 2 * (y_pred - y_true) / y_true.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-entropy loss\n",
    "class CE(Losses):\n",
    "    def loss(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "        loss = y_true * torch.log(y_pred)\n",
    "        return - loss.sum().item() / len(y_true)\n",
    "\n",
    "    def __call__(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "        return self.loss(y_pred, y_true)\n",
    "\n",
    "    def backward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return - (y_true / y_pred) / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers: list[Layer], loss_f: Losses = None):\n",
    "        self.layers = layers[1:] # do not save the input layer\n",
    "        self.loss_f = MSE() if loss_f is None else loss_f\n",
    "\n",
    "        # initialize all parameters\n",
    "        out = layers[0].construct()\n",
    "        for layer in self.layers:\n",
    "            out = layer.construct(out)\n",
    "\n",
    "    def copy_parameters(self, parameters) -> None:\n",
    "        params = list(parameters())\n",
    "        for layer in self.layers:\n",
    "            if layer.is_trainable:\n",
    "                layer.set_params(params.pop(0), params.pop(0))\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        \n",
    "        Args:\n",
    "            x: tensor of shape (m_samples, n_input_features).\n",
    "            \n",
    "        Return:\n",
    "            y_pred: tensor of shape (m_samples, n_out_features).\n",
    "        \"\"\"\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "\n",
    "    def __forward__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer.__forward__(out)\n",
    "        return out\n",
    "    \n",
    "    def evaluate(self, x: torch.Tensor, y: torch.Tensor) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model between input x and target y.\n",
    "        \n",
    "        Args:\n",
    "            x: tensor (m_samples, n_input_features).\n",
    "            y: target tensor (m_samples, n_out_features).\n",
    "            \n",
    "        Return:\n",
    "            loss: error between y_pred and target y.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        return self.loss_f(y_pred, y)\n",
    "    \n",
    "    def update(self, y_pred: torch.Tensor, y_true: torch.Tensor, lr: float) -> None:\n",
    "        delta = self.loss_f.backward(y_pred, y_true)\n",
    "        for layer in reversed(self.layers):\n",
    "            delta = layer.backward(delta, lr)\n",
    "\n",
    "    def fit(self, x_train: torch.Tensor, y_train: torch.Tensor, \n",
    "        epochs: int, lr: float, batch_size: int, \n",
    "        x_valid: torch.Tensor, y_valid: torch.Tensor):\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss_t = [] # train loss\n",
    "            for batch in range(0, len(y_train), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "\n",
    "                y_pred = self.__forward__(x_train[batch:end_batch])\n",
    "                loss_t.append(self.loss_f(y_pred, y_train[batch:end_batch]))\n",
    "\n",
    "                self.update(y_pred, y_train[batch:end_batch], lr)\n",
    "                \n",
    "            loss_t = sum(loss_t) / len(loss_t)\n",
    "            loss_v = self.evaluate(x_valid, y_valid) # valid loss\n",
    "            print('Epoch: {} - L: {:.4f} - L_v {:.4f}'.format(epoch, loss_t, loss_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchSequential(nn.Module):\n",
    "    def __init__(self, layers: list[nn.Module], loss_fn=None):\n",
    "        super(TorchSequential, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        for layer in self.layers:\n",
    "            layer.to(device)\n",
    "        self.loss_fn = loss_fn if loss_fn is not None else nn.MSELoss()\n",
    "        self.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.clone()\n",
    "        for l in self.layers:\n",
    "            out = l(out)\n",
    "        return out\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self(x)\n",
    "            return self.loss_fn(y_pred, y).item()\n",
    "        \n",
    "    def fit(self, x: torch.Tensor, y: torch.Tensor, \n",
    "            epochs: int, lr: float, batch_size: int, \n",
    "            x_valid: torch.Tensor, y_valid: torch.Tensor):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr, momentum=0.0)\n",
    "        for epoch in range(epochs):\n",
    "            loss_t = []\n",
    "            for batch in range(0, len(y), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                y_pred = self(x[batch:end_batch])\n",
    "                loss = self.loss_fn(y_pred, y[batch:end_batch])\n",
    "                loss_t.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            loss_t = sum(loss_t) / len(loss_t)\n",
    "            loss_v = self.evaluate(x_valid, y_valid)\n",
    "            print('Epoch: {} - L: {:.4f} - L_v {:.4f}'.format(epoch, loss_t, loss_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchSequential([\n",
    "    nn.Linear(N, 32), nn.ReLU(),\n",
    "    nn.Linear(32, 32), nn.ReLU(),\n",
    "    nn.Linear(32, 32), nn.ReLU(),\n",
    "    nn.Linear(32, CLASSES)\n",
    "], loss_fn=nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch vs Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([\n",
    "    InputLayer(N),\n",
    "    Dense(32), Relu(),\n",
    "    Dense(32), Relu(),\n",
    "    Dense(32), Relu(),\n",
    "    Dense(CLASSES), Softmax()\n",
    "], loss_f=CE())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tools.torch_metrics import torch_mape as mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.880857811020349"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without softmax layer in torch_model\n",
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4115675724158274"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with softmax layer in torch_model\n",
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    softmax(torch_model(X_valid))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.copy_parameters(torch_model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict after copy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.17368323091439"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without softmax layer in torch_model\n",
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with softmax layer in torch_model\n",
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    softmax(torch_model(X_valid))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.evaluate(X_valid, Y_valid),\n",
    "    torch_model.evaluate(X_valid, Y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR: float = 0.08\n",
    "EPOCHS: int = 32\n",
    "BATCH_SIZE: int = len(Y_train) // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - L: 1.1501 - L_v 1.0956\n",
      "Epoch: 1 - L: 1.1031 - L_v 1.0922\n",
      "Epoch: 2 - L: 1.0703 - L_v 1.0921\n",
      "Epoch: 3 - L: 1.0451 - L_v 1.0933\n",
      "Epoch: 4 - L: 1.0233 - L_v 1.0941\n",
      "Epoch: 5 - L: 1.0027 - L_v 1.0937\n",
      "Epoch: 6 - L: 0.9816 - L_v 1.0919\n",
      "Epoch: 7 - L: 0.9593 - L_v 1.0877\n",
      "Epoch: 8 - L: 0.9348 - L_v 1.0811\n",
      "Epoch: 9 - L: 0.9087 - L_v 1.0733\n",
      "Epoch: 10 - L: 0.8813 - L_v 1.0621\n",
      "Epoch: 11 - L: 0.8534 - L_v 1.0502\n",
      "Epoch: 12 - L: 0.8258 - L_v 1.0370\n",
      "Epoch: 13 - L: 0.7997 - L_v 1.0232\n",
      "Epoch: 14 - L: 0.7755 - L_v 1.0087\n",
      "Epoch: 15 - L: 0.7531 - L_v 0.9930\n",
      "Epoch: 16 - L: 0.7319 - L_v 0.9762\n",
      "Epoch: 17 - L: 0.7120 - L_v 0.9580\n",
      "Epoch: 18 - L: 0.6924 - L_v 0.9385\n",
      "Epoch: 19 - L: 0.6734 - L_v 0.9175\n",
      "Epoch: 20 - L: 0.6543 - L_v 0.8937\n",
      "Epoch: 21 - L: 0.6350 - L_v 0.8699\n",
      "Epoch: 22 - L: 0.6154 - L_v 0.8438\n",
      "Epoch: 23 - L: 0.5948 - L_v 0.8151\n",
      "Epoch: 24 - L: 0.5728 - L_v 0.7855\n",
      "Epoch: 25 - L: 0.5501 - L_v 0.7561\n",
      "Epoch: 26 - L: 0.5269 - L_v 0.7258\n",
      "Epoch: 27 - L: 0.5031 - L_v 0.6955\n",
      "Epoch: 28 - L: 0.4797 - L_v 0.6680\n",
      "Epoch: 29 - L: 0.4581 - L_v 0.6418\n",
      "Epoch: 30 - L: 0.4370 - L_v 0.6176\n",
      "Epoch: 31 - L: 0.4177 - L_v 0.5957\n"
     ]
    }
   ],
   "source": [
    "torch_model.fit(\n",
    "    X_train, Y_train.double(), \n",
    "    EPOCHS, LR, BATCH_SIZE, \n",
    "    X_valid, Y_valid.double()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - L: 1.1501 - L_v 1.0956\n",
      "Epoch: 1 - L: 1.1031 - L_v 1.0922\n",
      "Epoch: 2 - L: 1.0703 - L_v 1.0921\n",
      "Epoch: 3 - L: 1.0451 - L_v 1.0933\n",
      "Epoch: 4 - L: 1.0233 - L_v 1.0941\n",
      "Epoch: 5 - L: 1.0027 - L_v 1.0937\n",
      "Epoch: 6 - L: 0.9816 - L_v 1.0919\n",
      "Epoch: 7 - L: 0.9593 - L_v 1.0877\n",
      "Epoch: 8 - L: 0.9348 - L_v 1.0811\n",
      "Epoch: 9 - L: 0.9087 - L_v 1.0733\n",
      "Epoch: 10 - L: 0.8813 - L_v 1.0621\n",
      "Epoch: 11 - L: 0.8534 - L_v 1.0502\n",
      "Epoch: 12 - L: 0.8258 - L_v 1.0370\n",
      "Epoch: 13 - L: 0.7997 - L_v 1.0232\n",
      "Epoch: 14 - L: 0.7755 - L_v 1.0087\n",
      "Epoch: 15 - L: 0.7531 - L_v 0.9930\n",
      "Epoch: 16 - L: 0.7319 - L_v 0.9762\n",
      "Epoch: 17 - L: 0.7120 - L_v 0.9580\n",
      "Epoch: 18 - L: 0.6924 - L_v 0.9385\n",
      "Epoch: 19 - L: 0.6734 - L_v 0.9175\n",
      "Epoch: 20 - L: 0.6543 - L_v 0.8937\n",
      "Epoch: 21 - L: 0.6350 - L_v 0.8699\n",
      "Epoch: 22 - L: 0.6154 - L_v 0.8438\n",
      "Epoch: 23 - L: 0.5948 - L_v 0.8151\n",
      "Epoch: 24 - L: 0.5728 - L_v 0.7855\n",
      "Epoch: 25 - L: 0.5501 - L_v 0.7561\n",
      "Epoch: 26 - L: 0.5269 - L_v 0.7258\n",
      "Epoch: 27 - L: 0.5031 - L_v 0.6955\n",
      "Epoch: 28 - L: 0.4797 - L_v 0.6680\n",
      "Epoch: 29 - L: 0.4581 - L_v 0.6418\n",
      "Epoch: 30 - L: 0.4370 - L_v 0.6176\n",
      "Epoch: 31 - L: 0.4177 - L_v 0.5957\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH_SIZE, \n",
    "    X_valid, Y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict after train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.834234009540191e-16"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with softmax layer in torch_model\n",
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    softmax(torch_model(X_valid))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer #0\n",
      "1.250071876712616e-16\n",
      "layer #2\n",
      "6.13411172031106e-16\n",
      "layer #4\n",
      "1.897090067811492e-14\n",
      "layer #6\n",
      "5.825616298590782e-16\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(model.layers)):\n",
    "    if not model.layers[k].is_trainable:\n",
    "        continue\n",
    "    print(f'layer #{k}')\n",
    "    print(mape(model.layers[k].b, torch_model.layers[k].bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer #0\n",
      "2.6294144767891876e-16\n",
      "layer #2\n",
      "4.10756212331442e-15\n",
      "layer #4\n",
      "2.2525640882281767e-16\n",
      "layer #6\n",
      "3.4482271044222276e-16\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(model.layers)):\n",
    "    if not model.layers[k].is_trainable:\n",
    "        continue\n",
    "    print(f'layer #{k}')\n",
    "    print(mape(model.layers[k].w, torch_model.layers[k].weight.T))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
