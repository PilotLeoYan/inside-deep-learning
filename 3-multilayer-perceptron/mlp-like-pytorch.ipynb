{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP like PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/PilotLeoYan/inside-deep-learning/blob/main/3-multilayer-perceptron/mlp-like-pytorch.ipynb\">\n",
    "    <img src=\"../images/colab_logo.png\" width=\"32\">Open in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.org/github/PilotLeoYan/inside-deep-learning/blob/main/3-multilayer-perceptron/mlp-like-pytorch.ipynb\">\n",
    "    <img src=\"../images/jupyter_logo.png\" width=\"32\">Open in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook [3-1-mlp](3-1-mlp.ipynb), \n",
    "we made a single dense layer that contained its \n",
    "own activation function, so it is easy to explain backpropagation.\n",
    "But usually, the Dense layer and the Activation function layer are separated. \n",
    "In this notebook, we separate the Dense layer and the Activation function layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: black\">\n",
    "<img src=\"../images/mlp-2.png\" alt=\"deep neuronal network\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are not going to explain mathematics because, \n",
    "in essence, it is the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.13.5', '2.8.0+cu129')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from platform import python_version\n",
    "python_version(), torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_class(Class):  \n",
    "    \"\"\"Register functions as methods in created class.\"\"\"\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{X} \\in \\mathbb{R}^{m \\times n} \\\\\n",
    "\\mathbf{Y} \\in \\mathbb{R}^{m \\times n_{\\text{o}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 5)\n",
      "(10100,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "M: int = 10_100 # number of samples\n",
    "N: int = 5 # number of input features\n",
    "CLASSES: int = 3 # number of output classes\n",
    "\n",
    "X, Y = make_classification(\n",
    "    n_samples=M, \n",
    "    n_features=N, \n",
    "    n_classes=CLASSES, \n",
    "    n_informative=N - 1, \n",
    "    n_redundant=0\n",
    ")\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10100, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_hat = nn.functional.one_hot(\n",
    "    torch.tensor(Y, device=device).long(), \n",
    "    CLASSES\n",
    ").type(torch.float32)\n",
    "Y_hat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split dataset into train and valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 5]), torch.Size([10000, 5]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.tensor(X[:100], device=device)\n",
    "X_valid = torch.tensor(X[100:], device=device)\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 3]), torch.Size([10000, 3]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train, Y_valid = Y_hat[:100], Y_hat[100:]\n",
    "Y_train.shape, Y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delete raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del Y\n",
    "del Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    is_trainable: bool = False\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dense or full conect layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, units: int):\n",
    "        self.units = units\n",
    "        self.is_trainable = True\n",
    "\n",
    "    def set_params(self, w: torch.Tensor, b: torch.Tensor) -> None:\n",
    "        self.w.copy_(w.T.detach().clone())\n",
    "        self.b.copy_(b.detach().clone())\n",
    "\n",
    "    def construct(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Initialize the parameters\n",
    "        self.w := tensor (n_features, units).\n",
    "        self.b := tensor (units).\n",
    "        \n",
    "        Args:\n",
    "            x: input tensor of shape (m_samples, n_features).\n",
    "        \n",
    "        Return:\n",
    "            z: out tensor of shape (m_samples, units).\n",
    "        \"\"\"\n",
    "        n_features = x.shape[-1]\n",
    "        self.w = torch.randn(n_features, self.units, device=device)\n",
    "        self.b = torch.randn(self.units, device=device)\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute weighted sum Z = XW+b.\n",
    "        \n",
    "        Args:\n",
    "            x: input tensor of shape (m_samples, n_features).\n",
    "            \n",
    "        Return:\n",
    "            z: out tensor of shape (m_samples, units).\n",
    "        \"\"\"\n",
    "        return torch.matmul(x, self.w) + self.b\n",
    "\n",
    "    def __forward__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward propagation for training step.\"\"\"\n",
    "        self.input = x.clone()\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def backward(self, delta, lr: float) -> torch.Tensor:\n",
    "        # bias der and update\n",
    "        self.b -= lr * torch.sum(delta, axis=0)\n",
    "        # weight derivative (update weight after compute input der)\n",
    "        w_der = torch.matmul(self.input.T, delta)\n",
    "        # input derivative\n",
    "        delta = torch.matmul(delta, self.w.T)\n",
    "        # weight update\n",
    "        self.w -= lr * w_der\n",
    "        return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Layer):\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        #return torch.relu(z)\n",
    "        return torch.max(z, torch.zeros_like(z))\n",
    "    \n",
    "    def __forward__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        self.a = self.forward(z)\n",
    "        return self.a\n",
    "    \n",
    "    def construct(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(z)\n",
    "    \n",
    "    def backward(self, delta, lr: float):\n",
    "        return delta * (1 * (self.a > 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Layer):\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        #return torch.sigmoid(z)\n",
    "        return 1 / (1 + torch.exp(-z))\n",
    "    \n",
    "    def __forward__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        self.a = self.forward(z)\n",
    "        return self.a\n",
    "    \n",
    "    def construct(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(z)\n",
    "    \n",
    "    def backward(self, delta, lr: float):\n",
    "        return delta * (self.a * (1 - self.a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh(Layer):\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        #return torch.tanh(z)\n",
    "        exp = torch.exp(-2 * z)\n",
    "        return (1 - exp) / (1 + exp)\n",
    "    \n",
    "    def __forward__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        self.a = self.forward(z)\n",
    "        return self.a\n",
    "    \n",
    "    def construct(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(z)\n",
    "\n",
    "    def backward(self, delta, lr: float):\n",
    "        return delta * (1 - self.a**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(Layer):\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        exp = torch.exp(z - torch.max(z, dim=1, keepdims=True)[0])\n",
    "        return exp / exp.sum(1, keepdims=True)\n",
    "    \n",
    "    def __forward__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        self.a = self.forward(z)\n",
    "        return self.a\n",
    "    \n",
    "    def construct(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        return self.forward(z)\n",
    "    \n",
    "    def backward(self, delta, lr: float):\n",
    "        return self.a * (delta - (delta * self.a).sum(axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputLayer(Layer):\n",
    "    def __init__(self, n_input_features: int):\n",
    "        self.m = 10\n",
    "        self.n = n_input_features\n",
    "\n",
    "    def construct(self) -> torch.Tensor:\n",
    "        return torch.randn(self.m, self.n, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Losses:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Losses):\n",
    "    def loss(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "        return ((y_pred - y_true)**2).mean().item()\n",
    "\n",
    "    def __call__(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> float:\n",
    "        return self.loss(y_pred, y_true)\n",
    "\n",
    "    def backward(self, y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "        return 2 * (y_pred - y_true) / y_true.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers: list[Layer], loss_f: Losses = None):\n",
    "        self.layers = layers[1:] # do not save the input layer\n",
    "        self.loss_f = MSE() if loss_f is None else loss_f\n",
    "\n",
    "        # initialize all parameters\n",
    "        out = layers[0].construct()\n",
    "        for layer in self.layers:\n",
    "            out = layer.construct(out)\n",
    "\n",
    "    def copy_parameters(self, parameters) -> None:\n",
    "        params = list(parameters())\n",
    "        for layer in self.layers:\n",
    "            if layer.is_trainable:\n",
    "                layer.set_params(params.pop(0), params.pop(0))\n",
    "\n",
    "    def predict(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "        \n",
    "        Args:\n",
    "            x: tensor of shape (m_samples, n_input_features).\n",
    "            \n",
    "        Return:\n",
    "            y_pred: tensor of shape (m_samples, n_out_features).\n",
    "        \"\"\"\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer.forward(out)\n",
    "        return out\n",
    "\n",
    "    def __forward__(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer.__forward__(out)\n",
    "        return out\n",
    "    \n",
    "    def evaluate(self, x: torch.Tensor, y: torch.Tensor) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the model between input x and target y.\n",
    "        \n",
    "        Args:\n",
    "            x: tensor (m_samples, n_input_features).\n",
    "            y: target tensor (m_samples, n_out_features).\n",
    "            \n",
    "        Return:\n",
    "            loss: error between y_pred and target y.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        return self.loss_f(y_pred, y)\n",
    "    \n",
    "    def update(self, y_pred: torch.Tensor, y_true: torch.Tensor, lr: float) -> None:\n",
    "        delta = self.loss_f.backward(y_pred, y_true)\n",
    "        for layer in reversed(self.layers):\n",
    "            delta = layer.backward(delta, lr)\n",
    "\n",
    "    def fit(self, x_train: torch.Tensor, y_train: torch.Tensor, \n",
    "        epochs: int, lr: float, batch_size: int, \n",
    "        x_valid: torch.Tensor, y_valid: torch.Tensor):\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            loss_t = [] # train loss\n",
    "            for batch in range(0, len(y_train), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "\n",
    "                y_pred = self.__forward__(x_train[batch:end_batch])\n",
    "                loss_t.append(self.loss_f(y_pred, y_train[batch:end_batch]))\n",
    "\n",
    "                self.update(y_pred, y_train[batch:end_batch], lr)\n",
    "                \n",
    "            loss_t = sum(loss_t) / len(loss_t)\n",
    "            loss_v = self.evaluate(x_valid, y_valid) # valid loss\n",
    "            print('Epoch: {} - L: {:.4f} - L_v {:.4f}'.format(epoch, loss_t, loss_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchSequential(nn.Module):\n",
    "    def __init__(self, layers: list[nn.Module], loss_fn=None):\n",
    "        super(TorchSequential, self).__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        for layer in self.layers:\n",
    "            layer.to(device)\n",
    "        self.loss_fn = loss_fn if loss_fn is not None else nn.MSELoss()\n",
    "        self.eval()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x.clone()\n",
    "        for l in self.layers:\n",
    "            out = l(out)\n",
    "        return out\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = self(x)\n",
    "            return self.loss_fn(y_pred, y).item()\n",
    "        \n",
    "    def fit(self, x: torch.Tensor, y: torch.Tensor, \n",
    "            epochs: int, lr: float, batch_size: int, \n",
    "            x_valid: torch.Tensor, y_valid: torch.Tensor):\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr, momentum=0.0)\n",
    "        for epoch in range(epochs):\n",
    "            loss_t = []\n",
    "            for batch in range(0, len(y), batch_size):\n",
    "                end_batch = batch + batch_size\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                y_pred = self(x[batch:end_batch])\n",
    "                loss = self.loss_fn(y_pred, y[batch:end_batch])\n",
    "                loss_t.append(loss.item())\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            loss_t = sum(loss_t) / len(loss_t)\n",
    "            loss_v = self.evaluate(x_valid, y_valid)\n",
    "            print('Epoch: {} - L: {:.4f} - L_v {:.4f}'.format(epoch, loss_t, loss_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = TorchSequential([\n",
    "    nn.Linear(N, 32), nn.Tanh(),\n",
    "    nn.Linear(32, 32), nn.Sigmoid(),\n",
    "    nn.Linear(32, 32), nn.ReLU(),\n",
    "    nn.Linear(32, CLASSES), nn.Softmax(dim=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch vs Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([\n",
    "    InputLayer(N),\n",
    "    Dense(32), Tanh(),\n",
    "    Dense(32), Sigmoid(),\n",
    "    Dense(32), Relu(),\n",
    "    Dense(CLASSES), Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import MAPE modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "import importlib.util\n",
    "from collections.abc import Callable\n",
    "\n",
    "def import_mape(module_path: str = '..') -> Callable:\n",
    "    \"\"\"\n",
    "    Tries to import the 'torch_mape' function from a local project structure.\n",
    "    If it fails (ModuleNotFoundError), it assumes a cloud environment (like Colab),\n",
    "    downloads the module from GitHub, imports it, and returns the function.\n",
    "\n",
    "    Args:\n",
    "        module_path (str): The relative path to the project's root directory\n",
    "                           for the local search.\n",
    "\n",
    "    Returns:\n",
    "        The imported 'torch_mape' function, or None if it fails.\n",
    "    \"\"\"\n",
    "    GITHUB_RAW_URL = 'https://raw.githubusercontent.com/PilotLeoYan/inside-deep-learning/main/tools/torch_metrics.py'\n",
    "    MODULE_NAME = 'torch_metrics'\n",
    "    LOCAL_FILE_NAME = f'{MODULE_NAME}.py'\n",
    "\n",
    "    try:\n",
    "        # Attempt 1: Standard import (if the package is installed or in PYTHONPATH)\n",
    "        from tools.torch_metrics import torch_mape\n",
    "        print(\"‚úÖ Module 'tools.torch_metrics' successfully imported from the environment.\")\n",
    "        return torch_mape\n",
    "\n",
    "    except ModuleNotFoundError:\n",
    "        # Attempt 2: Search in the specified local path (original behavior)\n",
    "        # This is useful for local development without installing the package.\n",
    "        project_path = os.path.abspath(os.path.join(module_path))\n",
    "        if project_path not in sys.path:\n",
    "            sys.path.insert(0, project_path)\n",
    "\n",
    "        try:\n",
    "            from tools.torch_metrics import torch_mape\n",
    "            print(\"‚úÖ Local module 'tools.torch_metrics' imported after adjusting the path.\")\n",
    "            # Remove the added path to avoid side effects\n",
    "            sys.path.pop(0)\n",
    "            return torch_mape\n",
    "        except ModuleNotFoundError:\n",
    "            # If both local attempts fail, proceed with the download\n",
    "            if project_path in sys.path:\n",
    "                sys.path.pop(0) # Clean up the path if it was added\n",
    "            print(f\"‚ö†Ô∏è Local module not found. Proceeding to download from GitHub...\")\n",
    "\n",
    "    # Download and Dynamic Loading Logic}\n",
    "    if not os.path.exists(LOCAL_FILE_NAME):\n",
    "        try:\n",
    "            print(f\"‚¨áÔ∏è Downloading '{LOCAL_FILE_NAME}' from GitHub...\")\n",
    "            response = requests.get(GITHUB_RAW_URL)\n",
    "            response.raise_for_status()  # This will raise an error if the HTTP request failed\n",
    "            with open(LOCAL_FILE_NAME, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(response.text)\n",
    "            print(\"üëç Download complete.\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"‚ùå Error downloading the file: {e}\")\n",
    "            return None\n",
    "\n",
    "    # Dynamically load the module using importlib\n",
    "    spec = importlib.util.spec_from_file_location(MODULE_NAME, LOCAL_FILE_NAME)\n",
    "    dynamic_module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(dynamic_module)\n",
    "    \n",
    "    print(f\"‚úÖ Module '{MODULE_NAME}' successfully loaded from the downloaded file.\")\n",
    "    return dynamic_module.torch_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Local module 'tools.torch_metrics' imported after adjusting the path.\n"
     ]
    }
   ],
   "source": [
    "mape = import_mape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127.7639408908569"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.copy_parameters(torch_model.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict after copy parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.855010572052286e-15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2388192130091114e-14"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.evaluate(X_valid, Y_valid),\n",
    "    torch_model.evaluate(X_valid, Y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR: float = 0.08\n",
    "EPOCHS: int = 32\n",
    "BATCH_SIZE: int = len(Y_train) // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - L: 0.2346 - L_v 0.2230\n",
      "Epoch: 1 - L: 0.2308 - L_v 0.2222\n",
      "Epoch: 2 - L: 0.2272 - L_v 0.2216\n",
      "Epoch: 3 - L: 0.2240 - L_v 0.2213\n",
      "Epoch: 4 - L: 0.2211 - L_v 0.2213\n",
      "Epoch: 5 - L: 0.2184 - L_v 0.2215\n",
      "Epoch: 6 - L: 0.2161 - L_v 0.2219\n",
      "Epoch: 7 - L: 0.2140 - L_v 0.2225\n",
      "Epoch: 8 - L: 0.2123 - L_v 0.2233\n",
      "Epoch: 9 - L: 0.2107 - L_v 0.2241\n",
      "Epoch: 10 - L: 0.2095 - L_v 0.2251\n",
      "Epoch: 11 - L: 0.2084 - L_v 0.2261\n",
      "Epoch: 12 - L: 0.2075 - L_v 0.2271\n",
      "Epoch: 13 - L: 0.2068 - L_v 0.2280\n",
      "Epoch: 14 - L: 0.2062 - L_v 0.2289\n",
      "Epoch: 15 - L: 0.2057 - L_v 0.2298\n",
      "Epoch: 16 - L: 0.2053 - L_v 0.2307\n",
      "Epoch: 17 - L: 0.2050 - L_v 0.2315\n",
      "Epoch: 18 - L: 0.2048 - L_v 0.2322\n",
      "Epoch: 19 - L: 0.2045 - L_v 0.2328\n",
      "Epoch: 20 - L: 0.2044 - L_v 0.2333\n",
      "Epoch: 21 - L: 0.2042 - L_v 0.2338\n",
      "Epoch: 22 - L: 0.2040 - L_v 0.2342\n",
      "Epoch: 23 - L: 0.2039 - L_v 0.2346\n",
      "Epoch: 24 - L: 0.2038 - L_v 0.2349\n",
      "Epoch: 25 - L: 0.2036 - L_v 0.2352\n",
      "Epoch: 26 - L: 0.2035 - L_v 0.2354\n",
      "Epoch: 27 - L: 0.2034 - L_v 0.2356\n",
      "Epoch: 28 - L: 0.2033 - L_v 0.2358\n",
      "Epoch: 29 - L: 0.2031 - L_v 0.2359\n",
      "Epoch: 30 - L: 0.2030 - L_v 0.2360\n",
      "Epoch: 31 - L: 0.2029 - L_v 0.2361\n"
     ]
    }
   ],
   "source": [
    "torch_model.fit(\n",
    "    X_train, Y_train.double(), \n",
    "    EPOCHS, LR, BATCH_SIZE, \n",
    "    X_valid, Y_valid.double()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - L: 0.2346 - L_v 0.2230\n",
      "Epoch: 1 - L: 0.2308 - L_v 0.2222\n",
      "Epoch: 2 - L: 0.2272 - L_v 0.2216\n",
      "Epoch: 3 - L: 0.2240 - L_v 0.2213\n",
      "Epoch: 4 - L: 0.2211 - L_v 0.2213\n",
      "Epoch: 5 - L: 0.2184 - L_v 0.2215\n",
      "Epoch: 6 - L: 0.2161 - L_v 0.2219\n",
      "Epoch: 7 - L: 0.2140 - L_v 0.2225\n",
      "Epoch: 8 - L: 0.2123 - L_v 0.2233\n",
      "Epoch: 9 - L: 0.2107 - L_v 0.2241\n",
      "Epoch: 10 - L: 0.2095 - L_v 0.2251\n",
      "Epoch: 11 - L: 0.2084 - L_v 0.2261\n",
      "Epoch: 12 - L: 0.2075 - L_v 0.2271\n",
      "Epoch: 13 - L: 0.2068 - L_v 0.2280\n",
      "Epoch: 14 - L: 0.2062 - L_v 0.2289\n",
      "Epoch: 15 - L: 0.2057 - L_v 0.2298\n",
      "Epoch: 16 - L: 0.2053 - L_v 0.2307\n",
      "Epoch: 17 - L: 0.2050 - L_v 0.2315\n",
      "Epoch: 18 - L: 0.2048 - L_v 0.2322\n",
      "Epoch: 19 - L: 0.2045 - L_v 0.2328\n",
      "Epoch: 20 - L: 0.2044 - L_v 0.2333\n",
      "Epoch: 21 - L: 0.2042 - L_v 0.2338\n",
      "Epoch: 22 - L: 0.2040 - L_v 0.2342\n",
      "Epoch: 23 - L: 0.2039 - L_v 0.2346\n",
      "Epoch: 24 - L: 0.2038 - L_v 0.2349\n",
      "Epoch: 25 - L: 0.2036 - L_v 0.2352\n",
      "Epoch: 26 - L: 0.2035 - L_v 0.2354\n",
      "Epoch: 27 - L: 0.2034 - L_v 0.2356\n",
      "Epoch: 28 - L: 0.2033 - L_v 0.2358\n",
      "Epoch: 29 - L: 0.2031 - L_v 0.2359\n",
      "Epoch: 30 - L: 0.2030 - L_v 0.2360\n",
      "Epoch: 31 - L: 0.2029 - L_v 0.2361\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, Y_train, \n",
    "    EPOCHS, LR, BATCH_SIZE, \n",
    "    X_valid, Y_valid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict after train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.062701109984309e-15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape(\n",
    "    model.predict(X_valid),\n",
    "    torch_model(X_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer #0\n",
      "6.254439885966585e-16\n",
      "layer #2\n",
      "9.609444666672361e-15\n",
      "layer #4\n",
      "3.066545338705039e-14\n",
      "layer #6\n",
      "6.439646125804314e-14\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(model.layers)):\n",
    "    if not model.layers[k].is_trainable:\n",
    "        continue\n",
    "    print(f'layer #{k}')\n",
    "    print(mape(model.layers[k].b, torch_model.layers[k].bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer #0\n",
      "1.1386626503371084e-15\n",
      "layer #2\n",
      "2.9895800397901188e-15\n",
      "layer #4\n",
      "5.446107946404645e-15\n",
      "layer #6\n",
      "1.2322397275916085e-14\n"
     ]
    }
   ],
   "source": [
    "for k in range(len(model.layers)):\n",
    "    if not model.layers[k].is_trainable:\n",
    "        continue\n",
    "    print(f'layer #{k}')\n",
    "    print(mape(model.layers[k].w, torch_model.layers[k].weight.T))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv7 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
