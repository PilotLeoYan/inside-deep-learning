{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14d1c73",
   "metadata": {},
   "source": [
    "# Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea764f2",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/PilotLeoYan/inside-deep-learning/blob/main/0-premilinaries/gradient.ipynb\">\n",
    "    <img src=\"../images/colab_logo.png\" width=\"32\">Open in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://nbviewer.org/github/PilotLeoYan/inside-deep-learning/blob/main/0-premilinaries/gradient.ipynb\">\n",
    "    <img src=\"../images/jupyter_logo.png\" width=\"32\">Open in Jupyter NBViewer</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0297e3e9",
   "metadata": {},
   "source": [
    "In the field of machine learning, we will have to calculate the derivatives of multivariable functions.\n",
    "These derivatives can be grouped together under the term **gradient**. \n",
    "We will first use gradients to adjust the parameters of our machine learning models during gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94756db3",
   "metadata": {},
   "source": [
    "üõë It is assumed that the reader is already familiar with differentiating single variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe239823",
   "metadata": {},
   "source": [
    "$$\n",
    "\\nabla_{\\mathbf{x}}f = \\text{grad} f = \\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7ea19",
   "metadata": {},
   "source": [
    "**Purpose of this Notebook**:\n",
    "\n",
    "The purposes of this notebook are:\n",
    "1. Present the three types of layout conventions.\n",
    "2. Progress from the easiest level to the most difficult.\n",
    "3. Solve the examples at each level.\n",
    "4. Use the autograd module at each level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7172af13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.13.5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autograd import jacobian, numpy as np\n",
    "\n",
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55ac0f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our error function\n",
    "def mape(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Mean Absolute \n",
    "    \"\"\"\n",
    "    return np.mean(np.abs((a - b) / a)).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d455154",
   "metadata": {},
   "source": [
    "# Level 1 - vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77051f48",
   "metadata": {},
   "source": [
    "There are different layout conventions (numerator layout, denominator layout and mixed layout). \n",
    "Let's review each layout and then make a comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31592d73",
   "metadata": {},
   "source": [
    "For a function $f: \\mathbb{R}^{n} \\to \\mathbb{R}$, \n",
    "$\\mathbf{x} \\mapsto f(\\mathbf{x})$,\n",
    "$\\mathbf{x} \\in \\mathbb{R}^{n}$ we define the *gradient* of $f$ as\n",
    "$$\n",
    "\\nabla_{\\mathbf{x}}f = \\text{grad} f = \\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5e501",
   "metadata": {},
   "source": [
    "First, we need to calculate the size of the gradient. However, each layout defines a specific size.\n",
    "Therefore, we will examine each size in relation to its respective layout.\n",
    "We will use the same example for each layout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1adb8e",
   "metadata": {},
   "source": [
    "Example 1:\n",
    "For $\\mathbf{x} \\in \\mathbb{R}^{4}$, we have\n",
    "$$\n",
    "f(\\mathbf{x}) = 3 \\mathbf{x}^{\\top} \\mathbf{x}\n",
    "\\in \\mathbb{R}\n",
    "$$\n",
    "then, let's compute its gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55890834",
   "metadata": {},
   "source": [
    "## numerator layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8fd7df",
   "metadata": {},
   "source": [
    "The gradient in *numerator layout* is\n",
    "$$\n",
    "\\frac{\\mathrm{d} {\\color{Cyan} f}}\n",
    "{\\mathrm{d} {\\color{Magenta} \\mathbf{x}}} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{1}} &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{n}} \n",
    "\\end{bmatrix} \\in \n",
    "\\mathbb{R}^{{\\color{Cyan} 1} \\times {\\color{Magenta} n}}\n",
    "$$\n",
    "where the dimensionality/size of the gradient is the combination \n",
    "of the resulting size of $f$ $\\times$ the size of $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc4530",
   "metadata": {},
   "source": [
    "### example 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc358b",
   "metadata": {},
   "source": [
    "For our example 1, first, we need to calculate the size of the gradient as\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}}\n",
    "\\in \\mathbb{R}^{1 \\times 4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e349c2",
   "metadata": {},
   "source": [
    "Next, let's calculate the row vector as\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{1}} &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{2}} &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{3}} &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{4}}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf25975",
   "metadata": {},
   "source": [
    "Next, let's calculate the partial derivatives\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(\\mathbf{x}) &= 3 \\mathbf{x}\\top \\mathbf{x} \\\\\n",
    "&= 3 \\left( \n",
    "    x_{1}^{2} + x_{2}^{2} + x_{3}^{2} + x_{4}^{2}\n",
    "\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "therefore, the partial derivatives are\n",
    "$$\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial x_{1}} = 6x_{1} \\\\\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial x_{2}} = 6x_{2} \\\\\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial x_{3}} = 6x_{3} \\\\\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial x_{4}} = 6x_{4}\n",
    "$$\n",
    "or better in a general partial derivative\n",
    "$$\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial x_{i}} = 6x_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e849760",
   "metadata": {},
   "source": [
    "**Note**: It is often easier to formulate the derivatives this way instead of writing all the derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6479116a",
   "metadata": {},
   "source": [
    "Finally, we can compute the gradient of $f$\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}} &=\n",
    "63 \\begin{bmatrix}\n",
    "    x_{1} & x_{2} &\n",
    "    x_{3} & x_{4}\n",
    "\\end{bmatrix} \\\\\n",
    "&= 6 \\mathbf{x}^{\\top}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1e177",
   "metadata": {},
   "source": [
    "## denominator layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b210be66",
   "metadata": {},
   "source": [
    "The gradient in *denominator layout* is\n",
    "$$\n",
    "\\frac{\\mathrm{d} {\\color{Cyan} f}}\n",
    "{\\mathrm{d} {\\color{Magenta} \\mathbf{x}}} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{1}} &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{n}} \n",
    "\\end{bmatrix}^{\\top} \\in \n",
    "\\mathbb{R}^{{\\color{Magenta} n} \\times {\\color{Cyan} 1}}\n",
    "$$\n",
    "where the dimensionality/size of the gradient is the combination \n",
    "of the size of $\\mathbf{x}$ $\\times$ the resulting size of $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f78f0a",
   "metadata": {},
   "source": [
    "**Note**: You can see that the denominator layout is the transpose of the numerator layout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f074772c",
   "metadata": {},
   "source": [
    "### example 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c17127",
   "metadata": {},
   "source": [
    "For our example 1, first, we need to calculate the size of the gradient as\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}}\n",
    "\\in \\mathbb{R}^{4 \\times 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f36ebb2",
   "metadata": {},
   "source": [
    "Next, let's calculate the row vector as\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{1}} \\\\\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{2}} \\\\\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{3}} \\\\\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{4}}\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0aa22",
   "metadata": {},
   "source": [
    "Next, let's calculate the partial derivatives\n",
    "$$\n",
    "\\frac{\\partial f(\\mathbf{x})}{\\partial x_{i}} = 6x_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3fb09",
   "metadata": {},
   "source": [
    "Finally, we can compute the gradient of $f$\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}} =\n",
    "6 \\mathbf{x} \\in \\mathbb{R}^{4 \\times 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a8b45b",
   "metadata": {},
   "source": [
    "**Remark**: the size of the gradient is a column vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f373b50",
   "metadata": {},
   "source": [
    "## mixture layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e752821",
   "metadata": {},
   "source": [
    "Mixture layout does not differentiate between column vectors and row vectors, \n",
    "ignoring the ‚Äú1‚Äù axes that are often unnecessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95965294",
   "metadata": {},
   "source": [
    "The gradient in *mixture layout* is\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}\n",
    "{\\mathrm{d} {\\color{Magenta} \\mathbf{x}}} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{1}} &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{2}} &\n",
    "    \\cdots &\n",
    "    \\frac{\\partial f(\\mathbf{x})}{\\partial x_{n}} \n",
    "\\end{bmatrix} \\in \n",
    "\\mathbb{R}^{{\\color{Magenta} n}}\n",
    "$$\n",
    "where the dimensionality/size of the gradient is the size of $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2285d61",
   "metadata": {},
   "source": [
    "### example 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0f49d",
   "metadata": {},
   "source": [
    "For our example 1, first, we need to calculate the size of the gradient as\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}}\n",
    "\\in \\mathbb{R}^{4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368e63ef",
   "metadata": {},
   "source": [
    "We can compute the gradient of $f$\n",
    "$$\n",
    "\\frac{\\mathrm{d} f}{\\mathrm{d} \\mathbf{x}} =\n",
    "6 \\mathbf{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfca00a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_1_x = np.random.randn(4)\n",
    "\n",
    "def example_1_f(x: np.ndarray):\n",
    "    return 3 * (x.T @ x)\n",
    "\n",
    "example_1_f(example_1_x).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847bbb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.34851952,  -3.06929364, -13.585319  ,   9.49406441])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's compute the gradient using autograd.jacobian\n",
    "grad_1 = jacobian(example_1_f, 0)(example_1_x)\n",
    "grad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbed529b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.34851952,  -3.06929364, -13.585319  ,   9.49406441])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's calculate the gradient ourselves\n",
    "our_grad_1 = 6 * example_1_x\n",
    "our_grad_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc644573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's comparate both solution\n",
    "mape(grad_1, our_grad_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03053cbd",
   "metadata": {},
   "source": [
    "# Level 2 - matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95544bb9",
   "metadata": {},
   "source": [
    "For a function $\\mathbf{f}: \\mathbb{R}^{m} \\to \\mathbb{R}^{n}$, \n",
    "$\\mathbf{x} \\mapsto \\mathbf{f}(\\mathbf{x})$,\n",
    "$\\mathbf{x} \\in \\mathbb{R}^{m}$ we define the *Jacobian* of $\\mathbf{f}$ as\n",
    "$$\n",
    "\\mathbf{J} = \n",
    "\\nabla_{\\mathbf{x}}f = \\text{grad} \\mathbf{f} = \n",
    "\\frac{\\mathrm{d} \\mathbf{f}}{\\mathrm{d} \\mathbf{x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf27da",
   "metadata": {},
   "source": [
    "Next, we will see how the Jacobian is defined in numerator, denominator, and mixed layout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a66166e",
   "metadata": {},
   "source": [
    "Example 2:\n",
    "For $\\mathbf{x} \\in \\mathbb{R}^{4}$, we have\n",
    "$$\n",
    "\\mathbf{f}(\\mathbf{x}) = \n",
    "7 \\mathbf{A} \\mathbf{x}\n",
    "\\in \\mathbb{R}^{3}\n",
    "$$\n",
    "where $\\mathbf{A} \\in \\mathbb{R}^{3 \\times 4}$.\n",
    "\n",
    "Then, let's compute its gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7b1f4",
   "metadata": {},
   "source": [
    "## numerator layout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dbf73b",
   "metadata": {},
   "source": [
    "The Jacobian of a function $\\mathbf{f}: \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$\n",
    "in *numerator layout* is\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbf{J} &= \n",
    "\\frac{\\mathrm{d} {\\color{Cyan} \\mathbf{f}}}\n",
    "{\\mathrm{d} {\\color{Magenta} \\mathbf{x}}} = \n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial \\mathbf{f}(\\mathbf{x})}{\\partial x_{1}}\n",
    "    & \\cdots &\n",
    "    \\frac{\\partial \\mathbf{f}(\\mathbf{x})}{\\partial x_{n}} \\\\\n",
    "\\end{bmatrix} \\\\ &=\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f_{1}(\\mathbf{x})}{\\partial \\mathbf{x}}\n",
    "    \\\\ \\vdots \\\\\n",
    "    \\frac{\\partial f_{m}(\\mathbf{x})}{\\partial \\mathbf{x}} \\\\\n",
    "\\end{bmatrix} \\\\ &=\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f_{1}(\\mathbf{x})}{\\partial x_{1}}\n",
    "    & \\cdots &\n",
    "    \\frac{\\partial f_{1}(\\mathbf{x})}{\\partial x_{n}}\n",
    "    \\\\ \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{\\partial f_{m}(\\mathbf{x})}{\\partial x_{1}}\n",
    "    & \\cdots & \n",
    "    \\frac{\\partial f_{m}(\\mathbf{x})}{\\partial x_{n}}\n",
    "\\end{bmatrix}\n",
    "\\in \n",
    "\\mathbb{R}^{{\\color{Cyan} m} \\times {\\color{Magenta} n}}\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7a2e63",
   "metadata": {},
   "source": [
    "**Note**: if $m = 1$, then we have $J \\in \\mathbb{R}^{1 \\times n}$\n",
    "like Level 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00238cb2",
   "metadata": {},
   "source": [
    "**Remark**: \n",
    "$$\n",
    "\\frac{\\partial \\mathbf{f}(\\mathbf{x})}{\\partial x_{i}} =\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f_{1}(\\mathbf{x})}{\\partial x_{i}}\n",
    "    \\\\ \\vdots \\\\\n",
    "    \\frac{\\partial f_{m}(\\mathbf{x})}{\\partial x_{i}}\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{m \\times 1}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial f_{i}(\\mathbf{x})}{\\partial \\mathbf{x}} =\n",
    "\\begin{bmatrix}\n",
    "    \\frac{\\partial f_{i}(\\mathbf{x})}{\\partial x_{1}}\n",
    "    & \\cdots &\n",
    "    \\frac{\\partial f_{i}(\\mathbf{x})}{\\partial x_{n}}\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{1 \\times n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c5db93",
   "metadata": {},
   "source": [
    "### example 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2c3e5",
   "metadata": {},
   "source": [
    "For our example 2, first, we need to calculate the size of the Jacobian as\n",
    "$$\n",
    "\\frac{\\mathrm{d} \\mathbf{f}}{\\mathrm{d} \\mathbf{x}}\n",
    "\\in \\mathbb{R}^{3 \\times 4}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9801f",
   "metadata": {},
   "source": [
    "# üñãÔ∏è TODO\n",
    "\n",
    "+ compute for $x\\in\\mathbb{R}^{m}$ and $f\\in\\mathbb{R}^{n}$\n",
    "+ chain rule \n",
    "+ compute for $x\\in\\mathbb{R}^{m \\times n}$ and $f\\in\\mathbb{R}$\n",
    "+ compute for $x\\in\\mathbb{R}^{m \\times n}$ and $f\\in\\mathbb{R}^{p}$\n",
    "+ compute for $x\\in\\mathbb{R}^{m \\times n}$ and $f\\in\\mathbb{R}^{p \\times q}$\n",
    "+ einstein summation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv7 (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
